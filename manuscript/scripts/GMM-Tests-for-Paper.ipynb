{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pdz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "import Bio\n",
    "from Bio import SeqIO,AlignIO\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods\n",
    "\n",
    "### \n",
    "### This includes code copied and pasted from the main methods used for the website in BioKlustering-Website/BioKlustering/mlmodel/parser/GMM.py\n",
    "### These methods are copy-pasted instead of directly included due to difficulties importing Django classes for running locally without running the server\n",
    "###\n",
    "\n",
    "def parseFasta(data):\n",
    "    d = {fasta.id : str(fasta.seq) for fasta in SeqIO.parse(data, \"fasta\")}\n",
    "    pd.DataFrame([d])\n",
    "    s = pd.Series(d, name='Sequence')\n",
    "    s.index.name = 'ID'\n",
    "    s.reset_index()\n",
    "    return pd.DataFrame(s)\n",
    "\n",
    "def get_kmer_table(path,k_min,k_max):\n",
    "    genes, gene_len, output_df = read_fasta(path)\n",
    "    count_vect = CountVectorizer(analyzer='char', ngram_range=(k_min, k_max))\n",
    "    X = count_vect.fit_transform(genes)\n",
    "    chars = count_vect.get_feature_names()\n",
    "    kmers = X.toarray()\n",
    "    kmer_freq = []\n",
    "    for i in range(len(genes)):\n",
    "        kmer_freq.append(kmers[i] / gene_len[i])\n",
    "    input = pd.DataFrame(kmer_freq, columns=chars)\n",
    "    return input, output_df\n",
    "\n",
    "def get_gene_sequences(filename):\n",
    "    genes = []\n",
    "    for record in SeqIO.parse(filename, \"fasta\"):\n",
    "        genes.append(str(record.seq))\n",
    "    return genes\n",
    "\n",
    "# genes: a list of gene sequences, which can directly be generated from get_gene_sequences().\n",
    "def get_gene_len(genes):\n",
    "    gene_len = []\n",
    "\n",
    "    for i in range(len(genes)):\n",
    "        gene_len.append(len(genes[i]))\n",
    "    return gene_len\n",
    "\n",
    "#read single fasta file containing all the gene sequences\n",
    "def read_fasta(path):\n",
    "    all_genes = []\n",
    "    all_gene_len = []\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    virus = parseFasta(path)\n",
    "    output_df = pd.concat([output_df, virus])\n",
    "    virus = virus.drop_duplicates(keep=\"last\")\n",
    "    genes = list(virus['Sequence'])\n",
    "    genes_seq = get_gene_sequences(path)\n",
    "    gene_len = get_gene_len(genes_seq)\n",
    "    all_genes = all_genes + genes_seq\n",
    "    all_gene_len = all_gene_len + gene_len\n",
    "    return all_genes, all_gene_len, output_df\n",
    "\n",
    "def get_predictions_default(path,k_min,k_max,num_class,cov_type):\n",
    "    seed  = np.random.seed(None)\n",
    "    ran_state = np.random.get_state()\n",
    "    kmer_table, output_df = get_kmer_table(path, k_min, k_max)\n",
    "    gmm = GMM(n_components=num_class,covariance_type=cov_type,random_state = seed).fit(kmer_table)\n",
    "    labels = gmm.predict(kmer_table)\n",
    "    return labels,ran_state\n",
    "\n",
    "def get_predictions_from_state(path,k_min,k_max,num_class,cov_type,state):\n",
    "    kmer_table, output_df = get_kmer_table(path, k_min, k_max)\n",
    "    gmm = GMM(n_components=num_class,covariance_type=cov_type,random_state = np.random.set_state(state)).fit(kmer_table)\n",
    "    labels = gmm.predict(kmer_table)\n",
    "    return labels\n",
    "\n",
    "def get_predictions(path,k_min,k_max,num_class,cov_type, seed):\n",
    "    kmer_table, output_df = get_kmer_table(path, k_min, k_max)\n",
    "    gmm = GMM(n_components=num_class, covariance_type=cov_type, random_state=seed).fit(kmer_table)\n",
    "    predictions = gmm.predict(kmer_table)\n",
    "    output_df.insert(0, \"Labels\", predictions)\n",
    "    return predictions\n",
    "\n",
    "def cal_accuracy(labels, predictions):\n",
    "    err = 0\n",
    "    total_len = len(labels)\n",
    "    for i in range(len(labels)):\n",
    "        if (labels[i] == -1):\n",
    "            total_len = total_len-1\n",
    "            continue\n",
    "        if (labels[i] != predictions[i]):\n",
    "            err += 1\n",
    "            \n",
    "    return 1-err/(total_len)\n",
    "\n",
    "def get_predictions_semi(path,k_min,k_max,num_class,cov_type,seed,labels):\n",
    "    targets = []\n",
    "    unique_given_labels = get_unique_numbers(labels)\n",
    "    if num_class < len(unique_given_labels) - 1 and -1 in unique_given_labels:\n",
    "        num_class = len(unique_given_labels) - 1\n",
    "    if num_class < len(unique_given_labels) and -1 not in unique_given_labels:\n",
    "        num_class = len(unique_given_labels)\n",
    "    kmer_table, output_df = get_kmer_table(path, k_min, k_max)\n",
    "\n",
    "    finalDf = pd.concat([kmer_table, labels], axis=1)\n",
    "    gmm = GMM(n_components=num_class, covariance_type=cov_type, random_state=seed)\n",
    "    for i in range(num_class):\n",
    "        if i in list(finalDf.Labels):\n",
    "            targets.append(i)\n",
    "    if len(targets) == num_class:\n",
    "        gmm.means_init = np.array([kmer_table[finalDf.Labels == i].mean(axis=0) for i in targets])\n",
    "    gmm.fit(kmer_table)\n",
    "    predictions = gmm.predict(kmer_table)\n",
    "\n",
    "    # Get the counts for the given labels and the predicted labels\n",
    "    given_labels_count = {}\n",
    "    labels_list = list(labels)\n",
    "    for label in unique_given_labels:\n",
    "        given_labels_count[label] = labels_list.count(label)\n",
    "    unique_predicted_labels = get_unique_numbers(predictions)\n",
    "    predicted_labels_count = {}\n",
    "    for label in unique_predicted_labels:\n",
    "        predicted_labels_count[label] = (predictions == label).sum()\n",
    "    max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "    if -1 in given_labels_count.keys():\n",
    "        del given_labels_count[-1]\n",
    "    given_labels_count = sorted(given_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Map the predicted labels to the given/actual labels\n",
    "    map_predict_to_actual = {}\n",
    "    max_value = max(unique_given_labels) + 1\n",
    "    for i in range(len(predicted_labels_count)):\n",
    "        if i < len(given_labels_count):\n",
    "            map_predict_to_actual[predicted_labels_count[i][0]] = given_labels_count[i][0]\n",
    "        else:\n",
    "            print(f\"{predicted_labels_count[i][0]} mapped to {max_value}\")\n",
    "            map_predict_to_actual[predicted_labels_count[i][0]] = max_value\n",
    "            max_value += 1\n",
    "    print(f\"map_predict_to_actual: {map_predict_to_actual}\")\n",
    "    predictions_final = []\n",
    "\n",
    "    # predictions_final contains the final results\n",
    "    # it takes care of the case when num_class > number of unique labels given\n",
    "    for i in range(len(predictions)):\n",
    "        if labels[i] == -1:\n",
    "            if predictions[i] in map_predict_to_actual.keys():\n",
    "                predictions_final.append(map_predict_to_actual[predictions[i]])\n",
    "            else:\n",
    "                predictions_final.append(map_predict_to_actual[max_item])\n",
    "        else:\n",
    "            predictions_final.append(labels[i])\n",
    "\n",
    "    predictions = np.array(predictions_final)\n",
    "    output_df.insert(0, \"Labels\", predictions)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def get_unique_numbers(numbers):\n",
    "    list_of_unique_numbers = []\n",
    "\n",
    "    unique_numbers = set(numbers)\n",
    "\n",
    "    for number in unique_numbers:\n",
    "        list_of_unique_numbers.append(number)\n",
    "\n",
    "    return list_of_unique_numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(path,labels,num_class):\n",
    "    best_accu = 0\n",
    "    best_prediction = []\n",
    "    cov_type = ['full','diag','tied','spherical']\n",
    "    k_min = [2,3,4,5]\n",
    "    k_max = [2,3,4,5]\n",
    "    for cov in cov_type:\n",
    "        for k1 in k_min:\n",
    "            for k2 in k_max:\n",
    "                if (k2 >= k1):\n",
    "                    prediction = get_predictions_semi(path,k1,k2,num_class,cov,0,labels)\n",
    "                    accu = cal_accuracy(labels,prediction)\n",
    "                    if accu > best_accu: \n",
    "                        best_accu = accu\n",
    "                        best_kmin = k1\n",
    "                        best_kmax = k2\n",
    "                        best_cov = cov\n",
    "                        best_prediction = prediction\n",
    "    print('Best model has the following parameters:')\n",
    "    print('minimum length of kmer: ', best_kmin)\n",
    "    print('maximum length of kmer: ', best_kmax)\n",
    "    print('covariance type: ', best_cov)\n",
    "    print('It has an accuracy regard to known labels of ',best_accu)\n",
    "    return best_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_plot(x,y,n_dim,path,title):\n",
    "    \n",
    "    # normalization of X is omitted, since it gives weird plots\n",
    "    pca = PCA(n_components=n_dim)\n",
    "    principalComponents = pca.fit_transform(x)\n",
    "    principalDf = pd.DataFrame(data = principalComponents,columns = ['principal component 1', 'principal component 2'])\n",
    "    finalDf = pd.concat([principalDf, pd.Series(y)], axis = 1)\n",
    "    finalDf.columns = ['principal component 1', 'principal component 2','target']\n",
    "    \n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "    ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "    ax.set_title('2 component PCA', fontsize = 20)\n",
    "    targets = [0,1]\n",
    "    colors = ['r', 'g']\n",
    "    for target, color in zip(targets,colors):\n",
    "        indicesToKeep = finalDf['target'] == target\n",
    "        ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "                   , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "                   , c = color)\n",
    "    ax.legend(targets)\n",
    "    #images.append(path)\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.title(title)\n",
    "    fig.savefig(path)\n",
    "    filenm = path.split(\"/\")[1].split(\".\")[0]\n",
    "    finalDf.to_csv('gmm/' + filenm + \"_PCA.csv\")\n",
    "    plt.close(fig)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(x,y,path,title):\n",
    "    tsne = TSNE()\n",
    "    tsne.random_state = 0\n",
    "    X_embedded = tsne.fit_transform(x)\n",
    "    sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y, legend='full')\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "    plt.title(title)\n",
    "    plt.savefig(path)   \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../datasets/combined_Bat_Cat_flu.fa\"\n",
    "gene,gene_len,ouput_df = read_fasta(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2341"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(gene_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(gene_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1613.9943820224719"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(gene_len)/len(gene_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bat_len = len(get_gene_sequences(\"../datasets/bat_flu.fa\"))\n",
    "cat_len = len(get_gene_sequences(\"../datasets/cat_flu.fa\"))\n",
    "zeros = [0]*bat_len\n",
    "labels_all = np.append(zeros, [1]*cat_len, axis=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../datasets/combined_Bat_Cat_flu.fa\"\n",
    "k_min = 2 \n",
    "k_max = 6 \n",
    "num_class = 2 \n",
    "cov_type = 'full' \n",
    "seed = 1232\n",
    "predictions1 = get_predictions(path,k_min,k_max,num_class,cov_type,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = list(range(1, len(predictions1)+1))\n",
    "df = pd.DataFrame(list(zip(number, predictions1)), \n",
    "               columns =['Number', 'Labels']) \n",
    "df.to_csv('predictions_unsup.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(list(zip(number, labels_all)), \n",
    "               columns =['Number', 'Labels']) \n",
    "df2.to_csv('actual_labels.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2471910112359551"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_accuracy(labels_all,predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aaaaaa</th>\n",
       "      <th>aaaaac</th>\n",
       "      <th>aaaaag</th>\n",
       "      <th>aaaaat</th>\n",
       "      <th>aaaac</th>\n",
       "      <th>aaaaca</th>\n",
       "      <th>...</th>\n",
       "      <th>ttttg</th>\n",
       "      <th>ttttga</th>\n",
       "      <th>ttttgc</th>\n",
       "      <th>ttttgg</th>\n",
       "      <th>ttttgt</th>\n",
       "      <th>ttttt</th>\n",
       "      <th>ttttta</th>\n",
       "      <th>tttttc</th>\n",
       "      <th>tttttg</th>\n",
       "      <th>tttttt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.163382</td>\n",
       "      <td>0.059133</td>\n",
       "      <td>0.023215</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.150594</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.164332</td>\n",
       "      <td>0.063025</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.148280</td>\n",
       "      <td>0.058126</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>0.006524</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133869</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.014726</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.119607</td>\n",
       "      <td>0.036309</td>\n",
       "      <td>0.009825</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.119944</td>\n",
       "      <td>0.040446</td>\n",
       "      <td>0.012552</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.113463</td>\n",
       "      <td>0.038801</td>\n",
       "      <td>0.013521</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.091489</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.076375</td>\n",
       "      <td>0.023422</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 5955 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           aa       aaa      aaaa     aaaaa    aaaaaa    aaaaac    aaaaag  \\\n",
       "0    0.163382  0.059133  0.023215  0.006570  0.000876  0.001752  0.001752   \n",
       "1    0.150594  0.057684  0.019815  0.005284  0.000881  0.001761  0.000881   \n",
       "2    0.164332  0.063025  0.020542  0.007937  0.002801  0.001867  0.001401   \n",
       "3    0.148280  0.058126  0.022539  0.006524  0.001779  0.001186  0.001186   \n",
       "4    0.133869  0.048193  0.014726  0.002677  0.000000  0.000000  0.001339   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "173  0.119607  0.036309  0.009825  0.002563  0.000427  0.000000  0.001282   \n",
       "174  0.119944  0.040446  0.012552  0.002325  0.000000  0.000465  0.001395   \n",
       "175  0.113463  0.038801  0.013521  0.001176  0.000588  0.000588  0.000000   \n",
       "176  0.091489  0.021277  0.004965  0.001418  0.000000  0.000000  0.000709   \n",
       "177  0.076375  0.023422  0.006110  0.001018  0.000000  0.001018  0.000000   \n",
       "\n",
       "       aaaaat     aaaac    aaaaca  ...     ttttg    ttttga    ttttgc  \\\n",
       "0    0.002190  0.002190  0.000876  ...  0.000438  0.000438  0.000000   \n",
       "1    0.001761  0.002642  0.001761  ...  0.002202  0.000881  0.000440   \n",
       "2    0.001867  0.004669  0.002801  ...  0.000934  0.000467  0.000000   \n",
       "3    0.002372  0.003559  0.003559  ...  0.002966  0.000593  0.000593   \n",
       "4    0.001339  0.003347  0.001339  ...  0.002008  0.002008  0.000000   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "173  0.000854  0.000854  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "174  0.000465  0.001860  0.001395  ...  0.001395  0.000465  0.000465   \n",
       "175  0.000000  0.002939  0.000588  ...  0.002352  0.000000  0.001176   \n",
       "176  0.000709  0.000000  0.000000  ...  0.000709  0.000000  0.000000   \n",
       "177  0.000000  0.003055  0.002037  ...  0.002037  0.000000  0.000000   \n",
       "\n",
       "       ttttgg    ttttgt     ttttt    ttttta    tttttc    tttttg    tttttt  \n",
       "0    0.000000  0.000000  0.000438  0.000000  0.000000  0.000438  0.000000  \n",
       "1    0.000000  0.000881  0.001761  0.000440  0.000881  0.000000  0.000440  \n",
       "2    0.000467  0.000000  0.000934  0.000000  0.000934  0.000000  0.000000  \n",
       "3    0.001186  0.000593  0.001779  0.000000  0.001186  0.000593  0.000000  \n",
       "4    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "173  0.000000  0.000000  0.000854  0.000000  0.000854  0.000000  0.000000  \n",
       "174  0.000000  0.000465  0.001860  0.000000  0.000930  0.000465  0.000465  \n",
       "175  0.000588  0.000588  0.001176  0.000000  0.000000  0.001176  0.000000  \n",
       "176  0.000000  0.000709  0.000709  0.000709  0.000000  0.000000  0.000000  \n",
       "177  0.001018  0.001018  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[178 rows x 5955 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0, output_df = get_kmer_table(\"../datasets/combined_Bat_Cat_flu.fa\",2,6)\n",
    "df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_0\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents,columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([principalDf, pd.Series(predictions1)], axis = 1)\n",
    "finalDf.columns = ['principal Component 1', 'Principal Component 2','Predicted Label']\n",
    "finalDf.to_csv('pca_unsup.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = pd.concat([principalDf, pd.Series(labels_all)], axis = 1)\n",
    "finalDf.columns = ['principal Component 1', 'Principal Component 2','True Label']\n",
    "finalDf.to_csv('pca_labels.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_plot(df_0,predictions1,2,'figures/pca_0.png','PCA of Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_plot(df_0,labels_all,2,'figures/pca_labels.png','PCA of All Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(df_0,predictions1,'figures/tsne_0.png','TSNE of Predictions from Unsupervised Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(df_0,labels_all,'figures/tsne_labels.png','TSNE of All Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_50 = pd.read_csv('../datasets/labels_fifty_percent.csv')\n",
    "labels_50 = pd.Series(labels_50['Labels'])\n",
    "path = \"../datasets/combined_Bat_Cat_flu.fa\"\n",
    "num_class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "Best model has the following parameters:\n",
      "minimum length of kmer:  2\n",
      "maximum length of kmer:  2\n",
      "covariance type:  full\n",
      "It has an accuracy regard to known labels of  1.0\n"
     ]
    }
   ],
   "source": [
    "predictions_50_0 = model_selection(path,labels_50,num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8146067415730337"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_accuracy(labels_all,predictions_50_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_50_0, output_df = get_kmer_table(\"../datasets/combined_Bat_Cat_flu.fa\",2,3)\n",
    "tsne_plot(df_50_0,predictions_50_0,'figures/tsne_50_best.png','TSNE of Predictions from 50% Known Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_plot(df_50_0,predictions_50_0,2,'figures/pca_50_best.png','PCA of Predictions from 50% Known Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_50_0\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents,columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([principalDf, pd.Series(predictions_50_0)], axis = 1)\n",
    "finalDf.columns = ['principal Component 1', 'Principal Component 2','Predicted Label']\n",
    "finalDf.to_csv('pca_50%.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(list(zip(number, predictions_50_0)), \n",
    "               columns =['Number', 'Labels']) \n",
    "df3.to_csv('predictions_50%_bestModel.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(df_50_0,predictions_50_0,'figures/tsne_50.png','TSNE of Predictions from 50% Known Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_10 = pd.read_csv('../datasets/labels_ten_percent.csv')\n",
    "labels_10 = pd.Series(labels_10['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {1: 1, 0: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "map_predict_to_actual: {0: 1, 1: 0}\n",
      "Best model has the following parameters:\n",
      "minimum length of kmer:  2\n",
      "maximum length of kmer:  2\n",
      "covariance type:  full\n",
      "It has an accuracy regard to known labels of  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6067415730337078"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_10_0 = model_selection(path,labels_10,num_class)\n",
    "cal_accuracy(labels_all,predictions_10_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10_0, output_df = get_kmer_table(\"../datasets/combined_Bat_Cat_flu.fa\",2,4)\n",
    "tsne_plot(df_10_0,predictions_10_0,'figures/tsne_10_best.png','TSNE of Predictions from 10% Known Labels')\n",
    "PCA_plot(df_10_0,predictions_10_0,2,'figures/pca_10_best.png','PCA of Predictions from 10% Known Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_10_0\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents,columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([principalDf, pd.Series(predictions_10_0)], axis = 1)\n",
    "finalDf.columns = ['principal Component 1', 'Principal Component 2','Predicted Label']\n",
    "finalDf.to_csv('pca_10%.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame(list(zip(number, predictions_10_0)), \n",
    "               columns =['Number', 'Labels']) \n",
    "df4.to_csv('predictions_10%_bestModel.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised 10% only 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_10_0 = pd.read_csv('../datasets/labels_ten_percent_only0s.csv')\n",
    "labels_10_0 = labels_10_0['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "0 mapped to 1\n",
      "map_predict_to_actual: {1: 0, 0: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "0 mapped to 1\n",
      "map_predict_to_actual: {1: 0, 0: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "0 mapped to 1\n",
      "map_predict_to_actual: {1: 0, 0: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "0 mapped to 1\n",
      "map_predict_to_actual: {1: 0, 0: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "0 mapped to 1\n",
      "map_predict_to_actual: {1: 0, 0: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "1 mapped to 1\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "Best model has the following parameters:\n",
      "minimum length of kmer:  2\n",
      "maximum length of kmer:  2\n",
      "covariance type:  full\n",
      "It has an accuracy regard to known labels of  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5393258426966292"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_10_only0 = model_selection(path,labels_10_0,num_class)\n",
    "cal_accuracy(labels_all,predictions_10_only0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10_only0, output_df = get_kmer_table(\"../datasets/combined_Bat_Cat_flu.fa\",2,3)\n",
    "tsne_plot(df_10_only0,predictions_10_only0,'figures/tsne_10_0_best.png','TSNE of Predictions from 10% Known Labels')\n",
    "PCA_plot(df_10_only0,predictions_10_only0,2,'figures/pca_10_0_best.png','PCA of Predictions from 10% Known Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame(list(zip(number, predictions_10_only0)), \n",
    "               columns =['Number', 'Labels']) \n",
    "df5.to_csv('predictions_10%_only0s_bestModel.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_10_only0\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents,columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([principalDf, pd.Series(predictions_10_only0)], axis = 1)\n",
    "finalDf.columns = ['principal Component 1', 'Principal Component 2','Predicted Label']\n",
    "finalDf.to_csv('pca_10%_only0.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2471910112359551"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Unsupervised\"\n",
    "cal_accuracy(labels_all,predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_50_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8146067415730337"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"50%\"\n",
    "cal_accuracy(labels_all,predictions_50_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_10_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6067415730337078"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"10%\"\n",
    "cal_accuracy(labels_all,predictions_10_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_10_only0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5393258426966292"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"10% only 0s\"\n",
    "cal_accuracy(labels_all,predictions_10_only0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e92538d6ae6a97f17e04bbb4e9b013398e3c18a0c65822e154983a17b15d638a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
