{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn import preprocessing \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import copy\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "\n",
    "### \n",
    "### This includes code copied and pasted from the main methods used for the website in BioKlustering-Website/BioKlustering/mlmodel/parser/kmeans.py\n",
    "### These methods are copy-pasted instead of directly included due to difficulties importing Django classes for running locally without running the server\n",
    "###\n",
    "\n",
    "def parseFasta(data):\n",
    "    d = {fasta.id : str(fasta.seq) for fasta in SeqIO.parse(data, \"fasta\")}\n",
    "    pd.DataFrame([d])\n",
    "\n",
    "    s = pd.Series(d, name='Sequence')\n",
    "    s.index.name = 'ID'\n",
    "    s.reset_index()\n",
    "    return pd.DataFrame(s)\n",
    "\n",
    "def kmerXTable(s, a, b):\n",
    "    tfid_vector = TfidfVectorizer(analyzer='char', ngram_range=(a,b))\n",
    "    s_hat = tfid_vector.fit_transform(s.Sequence)\n",
    "    kmerNames = tfid_vector.get_feature_names_out()\n",
    "    kmers = s_hat.toarray()\n",
    "    return pd.DataFrame(kmers,columns=kmerNames, index = s.index)\n",
    "    \n",
    "def kmeans(fasta, cNum, klength_min = 6, klength_max = 6, rNum = 50, seed=None):\n",
    "    inputData = parseFasta(fasta)\n",
    "#     temp = virus01.append(inputData)\n",
    "#     temp = temp.drop_duplicates(keep=\"last\")\n",
    "        \n",
    "    inputData[\"Sequence\"] = inputData[\"Sequence\"].apply(lambda x: x.replace(\"-\", \"\"))\n",
    "    kmerXTableInput = kmerXTable(inputData, klength_min, klength_max)\n",
    "        \n",
    "        \n",
    "    #km = KMeans(random_state = rNum, n_clusters = cNum)\n",
    "    #m.fit(kmerXTableInput) \n",
    "    #y_hat = km.predict(kmerXTableInput)\n",
    "    PCAembedding = PCA(n_components=10)\n",
    "    NkmerXTableInput = preprocessing.normalize(kmerXTableInput)\n",
    "    PCAembedding_low = PCAembedding.fit_transform(NkmerXTableInput)\n",
    "    \n",
    "    np.random.seed(rNum)\n",
    "    ms = MeanShift()\n",
    "    cluster_centers = ms.cluster_centers_\n",
    "\n",
    "    n_cluster_centers = len(cluster_centers)\n",
    "\n",
    "    import warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        kmms = KMeans(init = cluster_centers, n_clusters = n_cluster_centers, random_state=seed)\n",
    "        #kmms = KMeans(init = 'k-means++', n_clusters = 2, n_init=20, max_iter=600)\n",
    "        y_hat = kmms.fit_predict(PCAembedding_low)\n",
    "\n",
    "    if n_cluster_centers > cNum:\n",
    "        res = y_hat\n",
    "        unique_predicted_labels = get_unique_numbers(res)\n",
    "        predicted_labels_count = {}\n",
    "        for label in unique_predicted_labels:\n",
    "            predicted_labels_count[label] = (res == label).sum()\n",
    "        max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "        predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "        map_predict_to_actual = {}\n",
    "        max_value = cNum-1\n",
    "        for i in range(len(predicted_labels_count)):\n",
    "            if i < max_value:\n",
    "                map_predict_to_actual[predicted_labels_count[i][0]] = i\n",
    "            else:\n",
    "                print(f\"{predicted_labels_count[i][0]} mapped to {max_value}\")\n",
    "                map_predict_to_actual[predicted_labels_count[i][0]] = max_value\n",
    "\n",
    "        # predictions_final contains the final results\n",
    "        # it takes care of the case when num_class > number of unique labels given\n",
    "        predictions_final = []\n",
    "        print(f\"map_predict_to_actual: {map_predict_to_actual}\")\n",
    "        for i in range(len(res)):\n",
    "            if res[i] in map_predict_to_actual.keys():\n",
    "                predictions_final.append(map_predict_to_actual[res[i]])\n",
    "            else:\n",
    "                predictions_final.append(map_predict_to_actual[max_item])\n",
    "        print(predictions_final)\n",
    "        y_hat = np.array(predictions_final)\n",
    "\n",
    "        \n",
    "    return y_hat, kmerXTableInput\n",
    "        \n",
    "def kmeans_semiSupervised(fasta, y_hat, klength_min = 6, klength_max = 6, rNum = 50, cNum=2, seed=None, verbose=False):\n",
    "    inputData = parseFasta(fasta)\n",
    "    inputData[\"Sequence\"] = inputData[\"Sequence\"].apply(lambda x: x.replace(\"-\", \"\"))\n",
    "    kmerXTableInput = kmerXTable(inputData, klength_min, klength_max)\n",
    "    \n",
    "    PCAembedding = PCA(n_components=10)\n",
    "    NkmerXTableInput = preprocessing.normalize(kmerXTableInput)\n",
    "    PCAembedding_low = PCAembedding.fit_transform(NkmerXTableInput)\n",
    "    \n",
    "    np.random.seed(rNum)\n",
    "    ms = MeanShift()\n",
    "    ms.fit(PCAembedding_low)\n",
    "    cluster_centers = ms.cluster_centers_\n",
    "\n",
    "    n_cluster_centers = len(cluster_centers)\n",
    "    \n",
    "    print(\"n cluster centers\", n_cluster_centers)\n",
    "\n",
    "    import warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        kmms = KMeans(init = cluster_centers, n_clusters = n_cluster_centers, random_state= seed)\n",
    "        kmms_labels = kmms.fit_predict(PCAembedding_low)\n",
    "\n",
    "    if n_cluster_centers > cNum:\n",
    "        res = kmms_labels\n",
    "        unique_predicted_labels = get_unique_numbers(res)\n",
    "        predicted_labels_count = {}\n",
    "        for label in unique_predicted_labels:\n",
    "            predicted_labels_count[label] = (res == label).sum()\n",
    "        max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "        predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "        map_predict_to_actual = {}\n",
    "        max_value = cNum-1\n",
    "        for i in range(len(predicted_labels_count)):\n",
    "            if i < max_value:\n",
    "                map_predict_to_actual[predicted_labels_count[i][0]] = i\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"{predicted_labels_count[i][0]} mapped to {max_value}\")\n",
    "                map_predict_to_actual[predicted_labels_count[i][0]] = max_value\n",
    "\n",
    "        # predictions_final contains the final results\n",
    "        # it takes care of the case when num_class > number of unique labels given\n",
    "        predictions_final = []\n",
    "        if verbose:\n",
    "            print(f\"map_predict_to_actual: {map_predict_to_actual}\")\n",
    "        for i in range(len(res)):\n",
    "            if res[i] in map_predict_to_actual.keys():\n",
    "                predictions_final.append(map_predict_to_actual[res[i]])\n",
    "            else:\n",
    "                predictions_final.append(map_predict_to_actual[max_item])\n",
    "        kmms_labels = np.array(predictions_final)\n",
    "\n",
    "     # convert all clusters into two clusters\n",
    "    kmerXTableInput[\"pLabels\"] = kmms_labels\n",
    "    kmerXTableInput[\"aLabels\"] = actual_labels = y_hat\n",
    "\n",
    "    # Get the counts for the given labels and the predicted labels\n",
    "    given_labels_count = {}\n",
    "    labels_list = list(actual_labels)\n",
    "    unique_given_labels = get_unique_numbers(actual_labels)\n",
    "    predictions = kmms_labels\n",
    "    for label in unique_given_labels:\n",
    "        given_labels_count[label] = labels_list.count(label)\n",
    "    unique_predicted_labels = get_unique_numbers(predictions)\n",
    "    predicted_labels_count = {}\n",
    "    for label in unique_predicted_labels:\n",
    "        predicted_labels_count[label] = (predictions == label).sum()\n",
    "    max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "    if -1 in given_labels_count.keys():\n",
    "        del given_labels_count[-1]\n",
    "    given_labels_count = sorted(given_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    res = np.array(predictions)\n",
    "    \n",
    "    # Map the predicted labels to the given/actual labels\n",
    "    unselected_given = copy.deepcopy(unique_given_labels)\n",
    "    if -1 in unselected_given:\n",
    "        unselected_given.remove(-1)\n",
    "    unselected_pred = copy.deepcopy(unique_predicted_labels)\n",
    "    \n",
    "    print(\"unselected pred \", unselected_pred)\n",
    "    print(\"unselected given \", unselected_given)\n",
    "\n",
    "    # Map the predicted labels to the given/actual labels\n",
    "    map_predict_to_actual = {}\n",
    "    for label_GIVEN_dict_entry in given_labels_count:\n",
    "        label_GIVEN = label_GIVEN_dict_entry[0]\n",
    "        predicted_labels_count_GIVEN = {}\n",
    "        label_GIVEN_idx = [index for (index, item) in enumerate(labels_list) if item == label_GIVEN]\n",
    "        res_GIVEN = [res[i] for i in label_GIVEN_idx]\n",
    "        unique_predicted_labels_GIVEN = list(set(get_unique_numbers(res_GIVEN)) & set(unselected_pred))\n",
    "        if len(unique_predicted_labels_GIVEN) == 0:\n",
    "                        continue\n",
    "        for lab in unique_predicted_labels_GIVEN:\n",
    "            predicted_labels_count_GIVEN[lab] = (res_GIVEN == lab).sum()\n",
    "        max_pred = max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get)\n",
    "        map_predict_to_actual[max_pred] = label_GIVEN\n",
    "        unselected_given.remove(label_GIVEN)\n",
    "        unselected_pred.remove(max_pred)\n",
    "            \n",
    "    # in the case where multiple given labels completely map to the same \n",
    "    # predicted label, we need to finish assigning given labels to any \n",
    "    # predicted label\n",
    "    for lab_remain in unselected_given:\n",
    "        for upl in unique_predicted_labels:\n",
    "            if upl not in map_predict_to_actual.keys():\n",
    "                map_predict_to_actual[upl] = lab_remain\n",
    "                unselected_given.remove(lab_remain)\n",
    "                unselected_pred.remove(upl)\n",
    "                break\n",
    "    \n",
    "    if len(unique_given_labels) <= cNum:\n",
    "        max_value = max(unique_given_labels) + 1\n",
    "        for upl in unique_predicted_labels:\n",
    "            if upl not in map_predict_to_actual.keys():\n",
    "                # print(f\"{upl} mapped to {max_value}\")\n",
    "                map_predict_to_actual[upl] = max_value\n",
    "                max_value += 1\n",
    "                unselected_pred.remove(upl)\n",
    "                \n",
    "    print(\"unselected pred \", unselected_pred)\n",
    "    print(\"unselected given \", unselected_given)\n",
    "                \n",
    "            \n",
    "    print(f\"map_predict_to_actual: {map_predict_to_actual}\")\n",
    "    if len(unselected_given) != len(unselected_pred):\n",
    "        print(\"error: num unselected given =\",len(unselected_given), \"!= unselected pred =\",len(unselected_pred))\n",
    "        \n",
    "    print(f\"map_predict_to_actual: {map_predict_to_actual}\")\n",
    "    \n",
    "    for l in range(min(len(unselected_pred),len(unselected_given))):\n",
    "        map_predict_to_actual[unselected_pred[l]] = unselected_given[l]\n",
    "        unselected_pred.remove(unselected_pred[l])\n",
    "        unselected_given.remove(unselected_pred[l])\n",
    "        \n",
    "    # this should never happen\n",
    "    #if len(unselected_pred) > 0 and len(unselected_given) == 0:\n",
    "    #    for unsel in unselected_pred:\n",
    "    #        map_predict_to_actual[unsel] = max_value\n",
    "            \n",
    "    # this can happen if there are fewer predicted labels than given\n",
    "    #if len(unselected_pred) == 0 and len(unselected_given) > 0:\n",
    "    #    for unsel in unselected_given:\n",
    "    #        map_predict_to_actual[-1] = unsel\n",
    "    \n",
    "    predictions_final = []\n",
    "    predictions_tmp = []\n",
    "\n",
    "    # predictions_final contains the final results\n",
    "    # it takes care of the case when num_class > number of unique labels given\n",
    "    for i in range(len(predictions)):\n",
    "        if actual_labels[i] == -1:\n",
    "            if predictions[i] in map_predict_to_actual.keys():\n",
    "                predictions_final.append(map_predict_to_actual[predictions[i]])\n",
    "                predictions_tmp.append(map_predict_to_actual[predictions[i]])\n",
    "            else:\n",
    "                predictions_final.append(map_predict_to_actual[max_item])\n",
    "                predictions_tmp.append(map_predict_to_actual[max_item])\n",
    "        else:\n",
    "            predictions_tmp.append(map_predict_to_actual[predictions[i]])\n",
    "            predictions_final.append(actual_labels[i])\n",
    "    \n",
    "    newLabels = predictions_final\n",
    "\n",
    "    # get accuracy with regard to known labels\n",
    "\n",
    "    unknown_label = -1\n",
    "    total_labeled = 0\n",
    "    for i in range(len(actual_labels)):\n",
    "        if actual_labels[i] != unknown_label:\n",
    "            total_labeled = total_labeled + 1\n",
    "\n",
    "    correct_count = 0\n",
    "    temp_accuracy = 0\n",
    "    for k in range(len(actual_labels)):\n",
    "        if (actual_labels[k] != unknown_label):\n",
    "            if (actual_labels[k] == predictions_tmp[k]):\n",
    "                correct_count += 1\n",
    "    temp_accuracy = correct_count / total_labeled\n",
    "    \n",
    "    return newLabels, kmerXTableInput.drop(columns=[\"pLabels\", \"aLabels\"]), kmms_labels\n",
    "    \n",
    "\n",
    "# this method credit to Zhiwen\n",
    "def get_gene_sequences(filename):\n",
    "    genes = []\n",
    "    for record in SeqIO.parse(filename, \"fasta\"):\n",
    "        genes.append(str(record.seq))\n",
    "    return genes\n",
    "\n",
    "# added helper method for semi-supervised labeling\n",
    "def get_unique_numbers(numbers):\n",
    "\n",
    "    list_of_unique_numbers = []\n",
    "\n",
    "    unique_numbers = set(numbers)\n",
    "\n",
    "    for number in unique_numbers:\n",
    "        list_of_unique_numbers.append(number)\n",
    "\n",
    "    return list_of_unique_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nucleotides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n cluster centers 2\n",
      "unselected pred  [0, 1]\n",
      "unselected given  [0, 1]\n",
      "unselected pred  []\n",
      "unselected given  []\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "fasta = \"../combined_nucleotide.fasta\"\n",
    "labels_nuc = pd.Series(pd.read_csv(\"../combined_labels_nucleotide.csv\").Labels)\n",
    "k_min = 5\n",
    "k_max = 6\n",
    "cNum = 2\n",
    "seed = 32624222\n",
    "\n",
    "predictions_nuc, kmers, old_labels = kmeans_semiSupervised(fasta, labels_nuc, k_min, k_max, cNum=cNum, seed=seed)\n",
    "\n",
    "inputData = parseFasta(fasta)\n",
    "inputData[\"Sequence\"] = inputData[\"Sequence\"].apply(lambda x: x.replace(\"-\", \"\"))\n",
    "kmerXTableInput = kmerXTable(inputData, k_min, k_max)\n",
    "\n",
    "PCAembedding = PCA(n_components=2)\n",
    "NkmerXTableInput = preprocessing.normalize(kmerXTableInput)\n",
    "PCAembedding_low = PCAembedding.fit_transform(NkmerXTableInput)\n",
    "\n",
    "predictions_nuc = pd.Series(predictions_nuc)\n",
    "\n",
    "principalDf = pd.DataFrame(data = PCAembedding_low,columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([pd.Series(kmers.index), principalDf, predictions_nuc], axis = 1)\n",
    "finalDf.columns = ['ID','principal Component 1', 'principal Component 2','label']\n",
    "finalDf.to_csv('../results/nuc_kmeans_pca.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones:  25  out of  350\n",
      "Zeros:  341  out of  350\n"
     ]
    }
   ],
   "source": [
    "n_unlab = sum(labels_nuc == -1)\n",
    "\n",
    "print(\"Ones: \", sum(predictions_nuc), \" out of \", n_unlab)\n",
    "print(\"Zeros: \", sum(1- predictions_nuc), \" out of \", n_unlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amino Acids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n cluster centers 27\n",
      "unselected pred  [0, 1]\n",
      "unselected given  [0, 1]\n",
      "unselected pred  []\n",
      "unselected given  []\n",
      "map_predict_to_actual: {1: 0, 0: 1}\n",
      "map_predict_to_actual: {1: 0, 0: 1}\n"
     ]
    }
   ],
   "source": [
    "fasta = \"../combined_amino.fasta\"\n",
    "labels_am = pd.Series(pd.read_csv(\"../combined_labels_amino.csv\").Labels)\n",
    "k_min = 5\n",
    "k_max = 6\n",
    "cNum = 2\n",
    "seed = 32624\n",
    "\n",
    "predictions_am, kmers, old_labels = kmeans_semiSupervised(fasta, labels_am, k_min, k_max, cNum=cNum, seed=seed)\n",
    "\n",
    "inputData = parseFasta(fasta)\n",
    "inputData[\"Sequence\"] = inputData[\"Sequence\"].apply(lambda x: x.replace(\"-\", \"\"))\n",
    "kmerXTableInput = kmerXTable(inputData, k_min, k_max)\n",
    "\n",
    "PCAembedding = PCA(n_components=2)\n",
    "NkmerXTableInput = preprocessing.normalize(kmerXTableInput)\n",
    "PCAembedding_low = PCAembedding.fit_transform(NkmerXTableInput)\n",
    "\n",
    "predictions_am= pd.Series(predictions_am)\n",
    "\n",
    "principalDf = pd.DataFrame(data = PCAembedding_low,columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([pd.Series(kmers.index), principalDf, predictions_am], axis = 1)\n",
    "finalDf.columns = ['ID','principal Component 1', 'principal Component 2','label']\n",
    "finalDf.to_csv('../results/am_kmeans_pca.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones:  423  out of  465\n",
      "Zeros:  58  out of  465\n"
     ]
    }
   ],
   "source": [
    "n_unlab = sum(labels_am == -1)\n",
    "\n",
    "print(\"Ones: \", sum(predictions_am), \" out of \", n_unlab)\n",
    "print(\"Zeros: \", sum(1- predictions_am), \" out of \", n_unlab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
