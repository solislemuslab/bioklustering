{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pdz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "import Bio\n",
    "from Bio import SeqIO,AlignIO\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# methods\n",
    "\n",
    "### \n",
    "### This includes code copied and pasted from the main methods used for the website in BioKlustering-Website/BioKlustering/mlmodel/parser/GMM.py\n",
    "### These methods are copy-pasted instead of directly included due to difficulties importing Django classes for running locally without running the server\n",
    "###\n",
    "\n",
    "def parseFasta(data):\n",
    "    d = {fasta.id : str(fasta.seq) for fasta in SeqIO.parse(data, \"fasta\")}\n",
    "    pd.DataFrame([d])\n",
    "    s = pd.Series(d, name='Sequence')\n",
    "    s.index.name = 'ID'\n",
    "    s.reset_index()\n",
    "    return pd.DataFrame(s)\n",
    "\n",
    "def get_kmer_table(path,k_min,k_max):\n",
    "    genes, gene_len, output_df = read_fasta(path)\n",
    "    count_vect = CountVectorizer(analyzer='char', ngram_range=(k_min, k_max))\n",
    "    X = count_vect.fit_transform(genes)\n",
    "    chars = count_vect.get_feature_names()\n",
    "    kmers = X.toarray()\n",
    "    kmer_freq = []\n",
    "    for i in range(len(genes)):\n",
    "        kmer_freq.append(kmers[i] / gene_len[i])\n",
    "    input = pd.DataFrame(kmer_freq, columns=chars)\n",
    "    return input, output_df\n",
    "\n",
    "def get_gene_sequences(filename):\n",
    "    genes = []\n",
    "    for record in SeqIO.parse(filename, \"fasta\"):\n",
    "        genes.append(str(record.seq))\n",
    "    return genes\n",
    "\n",
    "# genes: a list of gene sequences, which can directly be generated from get_gene_sequences().\n",
    "def get_gene_len(genes):\n",
    "    gene_len = []\n",
    "\n",
    "    for i in range(len(genes)):\n",
    "        gene_len.append(len(genes[i]))\n",
    "    return gene_len\n",
    "\n",
    "#read single fasta file containing all the gene sequences\n",
    "def read_fasta(path):\n",
    "    all_genes = []\n",
    "    all_gene_len = []\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    virus = parseFasta(path)\n",
    "    output_df = pd.concat([output_df, virus])\n",
    "    virus = virus.drop_duplicates(keep=\"last\")\n",
    "    genes = list(virus['Sequence'])\n",
    "    genes_seq = get_gene_sequences(path)\n",
    "    gene_len = get_gene_len(genes_seq)\n",
    "    all_genes = all_genes + genes_seq\n",
    "    all_gene_len = all_gene_len + gene_len\n",
    "    return all_genes, all_gene_len, output_df\n",
    "\n",
    "def get_predictions_default(path,k_min,k_max,num_class,cov_type):\n",
    "    seed  = np.random.seed(None)\n",
    "    ran_state = np.random.get_state()\n",
    "    kmer_table, output_df = get_kmer_table(path, k_min, k_max)\n",
    "    gmm = GMM(n_components=num_class,covariance_type=cov_type,random_state = seed).fit(kmer_table)\n",
    "    labels = gmm.predict(kmer_table)\n",
    "    return labels,ran_state\n",
    "\n",
    "def get_predictions_from_state(path,k_min,k_max,num_class,cov_type,state):\n",
    "    kmer_table, output_df = get_kmer_table(path, k_min, k_max)\n",
    "    gmm = GMM(n_components=num_class,covariance_type=cov_type,random_state = np.random.set_state(state)).fit(kmer_table)\n",
    "    labels = gmm.predict(kmer_table)\n",
    "    return labels\n",
    "\n",
    "def get_predictions(path,k_min,k_max,num_class,cov_type, seed):\n",
    "    kmer_table, output_df = get_kmer_table(path, k_min, k_max)\n",
    "    gmm = GMM(n_components=num_class, covariance_type=cov_type, random_state=seed).fit(kmer_table)\n",
    "    predictions = gmm.predict(kmer_table)\n",
    "    output_df.insert(0, \"Labels\", predictions)\n",
    "    return predictions\n",
    "\n",
    "def cal_accuracy(labels, predictions):\n",
    "    err = 0\n",
    "    total_len = len(labels)\n",
    "    for i in range(len(labels)):\n",
    "        if (labels[i] == -1):\n",
    "            total_len = total_len-1\n",
    "            continue\n",
    "        if (labels[i] != predictions[i]):\n",
    "            err += 1\n",
    "            \n",
    "    return 1-err/(total_len)\n",
    "\n",
    "def get_predictions_semi(path,k_min,k_max,num_class,cov_type,seed,labels):\n",
    "    targets = []\n",
    "    unique_given_labels = get_unique_numbers(labels)\n",
    "    if num_class < len(unique_given_labels) - 1 and -1 in unique_given_labels:\n",
    "        num_class = len(unique_given_labels) - 1\n",
    "    if num_class < len(unique_given_labels) and -1 not in unique_given_labels:\n",
    "        num_class = len(unique_given_labels)\n",
    "    kmer_table, output_df = get_kmer_table(path, k_min, k_max)\n",
    "\n",
    "    finalDf = pd.concat([kmer_table, labels], axis=1)\n",
    "    gmm = GMM(n_components=num_class, covariance_type=cov_type, random_state=seed)\n",
    "    for i in range(num_class):\n",
    "        if i in list(finalDf.Labels):\n",
    "            targets.append(i)\n",
    "    if len(targets) == num_class:\n",
    "        gmm.means_init = np.array([kmer_table[finalDf.Labels == i].mean(axis=0) for i in targets])\n",
    "    gmm.fit(kmer_table)\n",
    "    predictions = gmm.predict(kmer_table)\n",
    "\n",
    "    # Get the counts for the given labels and the predicted labels\n",
    "    given_labels_count = {}\n",
    "    labels_list = list(labels)\n",
    "    for label in unique_given_labels:\n",
    "        given_labels_count[label] = labels_list.count(label)\n",
    "    unique_predicted_labels = get_unique_numbers(predictions)\n",
    "    predicted_labels_count = {}\n",
    "    for label in unique_predicted_labels:\n",
    "        predicted_labels_count[label] = (predictions == label).sum()\n",
    "    max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "    if -1 in given_labels_count.keys():\n",
    "        del given_labels_count[-1]\n",
    "    given_labels_count = sorted(given_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    res = np.array(predictions)\n",
    "\n",
    "    # Map the predicted labels to the given/actual labels\n",
    "    unselected_given = copy.deepcopy(unique_given_labels)\n",
    "    if -1 in unselected_given:\n",
    "        unselected_given.remove(-1)\n",
    "    unselected_pred = copy.deepcopy(unique_predicted_labels)\n",
    "    map_predict_to_actual = {}\n",
    "    for label_GIVEN_dict_entry in given_labels_count:\n",
    "        label_GIVEN = label_GIVEN_dict_entry[0]\n",
    "        predicted_labels_count_GIVEN = {}\n",
    "        label_GIVEN_idx = [index for (index, item) in enumerate(labels_list) if item == label_GIVEN ]\n",
    "        res_GIVEN = [res[i] for i in label_GIVEN_idx]\n",
    "        unique_predicted_labels_GIVEN = list(set(get_unique_numbers(res_GIVEN)) & set(unselected_pred))\n",
    "        if len(unique_predicted_labels_GIVEN) == 0:\n",
    "            continue\n",
    "        for lab in unique_predicted_labels_GIVEN:\n",
    "            predicted_labels_count_GIVEN[lab] = (res_GIVEN == lab).sum()\n",
    "        map_predict_to_actual[max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get)] = label_GIVEN\n",
    "        unselected_given.remove(label_GIVEN)\n",
    "        to_rem = max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get)\n",
    "        unselected_pred.remove(to_rem)\n",
    "        print(\"remove \", label_GIVEN, \"from unselected given. \", unselected_given, \"remains\")\n",
    "        print(\"remove \", to_rem, \"from unselected pred. \", unselected_pred, \"remains\")\n",
    "\n",
    "\n",
    "    # in the case where multiple given labels completely map to the same \n",
    "    # predicted label, we need to finish assigning given labels to any \n",
    "    # predicted label\n",
    "    for lab_remain in unselected_given:\n",
    "        for upl in unique_predicted_labels:\n",
    "            if upl not in map_predict_to_actual.keys():\n",
    "                map_predict_to_actual[upl] = lab_remain\n",
    "                unselected_given.remove(lab_remain)\n",
    "                unselected_pred.remove(upl)\n",
    "                break\n",
    "\n",
    "    if len(unique_given_labels) < num_class:\n",
    "        max_value = max(unique_given_labels) + 1\n",
    "        for upl in unique_predicted_labels:\n",
    "            if upl not in map_predict_to_actual.keys():\n",
    "                # print(f\"{upl} mapped to {max_value}\")\n",
    "                map_predict_to_actual[upl] = max_value\n",
    "                max_value += 1\n",
    "                unselected_pred.remove(upl)\n",
    "    \n",
    "    if len(unselected_given) != len(unselected_pred):\n",
    "        print(\"unselected given != unselected pred\")\n",
    "        print(\"unselected pred: \", unselected_pred)\n",
    "        print(\"unselected given: \", unselected_given)\n",
    "    \n",
    "    \n",
    "    print(f\"map_predict_to_actual: {map_predict_to_actual}\")\n",
    "    predictions_final = []\n",
    "    predictions_tmp = []\n",
    "\n",
    "    # predictions_final contains the final results\n",
    "    # it takes care of the case when num_class > number of unique labels given\n",
    "    for i in range(len(predictions)):\n",
    "        if labels[i] == -1:\n",
    "            if predictions[i] in map_predict_to_actual.keys():\n",
    "                predictions_final.append(map_predict_to_actual[predictions[i]])\n",
    "                predictions_tmp.append(map_predict_to_actual[predictions[i]])\n",
    "            else:\n",
    "                predictions_final.append(map_predict_to_actual[max_item])\n",
    "                predictions_tmp.append(map_predict_to_actual[max_item])\n",
    "        else:\n",
    "            predictions_tmp.append(map_predict_to_actual[predictions[i]])\n",
    "            predictions_final.append(labels[i])\n",
    "\n",
    "    # get accuracy with regard to known labels\n",
    "\n",
    "    unknown_label = -1\n",
    "    total_labeled = 0\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] != unknown_label:\n",
    "            total_labeled = total_labeled + 1\n",
    "\n",
    "    correct_count = 0\n",
    "    temp_accuracy = 0\n",
    "    for k in range(len(labels)):\n",
    "        if (labels[k] != unknown_label):\n",
    "            if (labels[k] == predictions_tmp[k]):\n",
    "                correct_count += 1\n",
    "    temp_accuracy = correct_count / total_labeled\n",
    "\n",
    "\n",
    "    predictions = np.array(predictions_final)\n",
    "    output_df.insert(0, \"Labels\", predictions)\n",
    "    return predictions,temp_accuracy\n",
    "\n",
    "\n",
    "def get_unique_numbers(numbers):\n",
    "    list_of_unique_numbers = []\n",
    "\n",
    "    unique_numbers = set(numbers)\n",
    "\n",
    "    for number in unique_numbers:\n",
    "        list_of_unique_numbers.append(number)\n",
    "\n",
    "    return list_of_unique_numbers\n",
    "\n",
    "def model_selection(path,labels,num_class):\n",
    "    best_accu = 0\n",
    "    best_prediction = []\n",
    "    cov_type = ['full','diag','tied','spherical']\n",
    "    k_min = [2,3,4,5]\n",
    "    k_max = [2,3,4,5]\n",
    "    for cov in cov_type:\n",
    "        for k1 in k_min:\n",
    "            for k2 in k_max:\n",
    "                if (k2 >= k1):\n",
    "                    prediction,accu = get_predictions_semi(path,k1,k2,num_class,cov,0,labels)\n",
    "                    #accu = cal_accuracy(labels,prediction)\n",
    "                    if accu > best_accu: \n",
    "                        best_accu = accu\n",
    "                        best_kmin = k1\n",
    "                        best_kmax = k2\n",
    "                        best_cov = cov\n",
    "                        best_prediction = prediction\n",
    "    print('Best model has the following parameters:')\n",
    "    print('minimum length of kmer: ', best_kmin)\n",
    "    print('maximum length of kmer: ', best_kmax)\n",
    "    print('covariance type: ', best_cov)\n",
    "    print('It has an accuracy regard to known labels of ',best_accu)\n",
    "    return best_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nucleotides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/samoz/Documents/masters/research/bioklustering2/bioklustering/new_analysis_2024/scripts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove  0 from unselected given.  [1] remains\n",
      "remove  0 from unselected pred.  [1] remains\n",
      "remove  1 from unselected given.  [] remains\n",
      "remove  1 from unselected pred.  [] remains\n",
      "map_predict_to_actual: {0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "path = \"../combined_nucleotide.fasta\"\n",
    "labels_nuc = pd.read_csv(\"../combined_labels_nucleotide.csv\")\n",
    "labels_nuc = pd.Series(labels_nuc['Labels'])\n",
    "k_min = 2\n",
    "k_max = 3 \n",
    "num_class = 2 \n",
    "cov_type = 'full' \n",
    "seed = 1232\n",
    "predictions_nuc, tmp = get_predictions_semi(path, k_min, k_max, num_class, cov_type, seed, labels_nuc) #model_selection(path,labels_nuc,num_class)\n",
    "\n",
    "df_nuc, output_df = get_kmer_table(path,k_min,k_max)\n",
    "x = df_nuc\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents,columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([pd.Series(output_df.index), principalDf, pd.Series(predictions_nuc)], axis = 1)\n",
    "finalDf.columns = ['ID','principal Component 1', 'principal Component 2','label']\n",
    "finalDf.to_csv('../results/nuc_gmm_pca.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones:  201  out of  350\n",
      "Zeros:  165  out of  350\n"
     ]
    }
   ],
   "source": [
    "n_unlab = sum(labels_nuc == -1)\n",
    "\n",
    "print(\"Ones: \", sum(predictions_nuc), \" out of \", n_unlab)\n",
    "print(\"Zeros: \", sum(1- predictions_nuc), \" out of \", n_unlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amino Acids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove  0 from unselected given.  [1] remains\n",
      "remove  1 from unselected pred.  [0] remains\n",
      "remove  1 from unselected given.  [] remains\n",
      "remove  0 from unselected pred.  [] remains\n",
      "map_predict_to_actual: {1: 0, 0: 1}\n"
     ]
    }
   ],
   "source": [
    "path = \"../combined_amino.fasta\"\n",
    "labels_am = pd.read_csv(\"../combined_labels_amino.csv\")\n",
    "labels_am = pd.Series(labels_am['Labels'])\n",
    "k_min = 2\n",
    "k_max = 3\n",
    "num_class = 2 \n",
    "cov_type = 'full' \n",
    "seed = 1232\n",
    "predictions_am, tmp = get_predictions_semi(path, k_min, k_max, num_class, cov_type, seed, labels_am) #model_selection(path,labels_am,num_class)\n",
    "\n",
    "df_am, output_df = get_kmer_table(path,k_min,k_max)\n",
    "x = df_am\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents,columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([pd.Series(output_df.index), principalDf, pd.Series(predictions_am)], axis = 1)\n",
    "finalDf.columns = ['ID','principal Component 1', 'principal Component 2','label']\n",
    "finalDf.to_csv('../results/am_gmm_pca.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones:  444  out of  465\n",
      "Zeros:  37  out of  465\n"
     ]
    }
   ],
   "source": [
    "n_unlab = sum(labels_am == -1)\n",
    "\n",
    "print(\"Ones: \", sum(predictions_am), \" out of \", n_unlab)\n",
    "print(\"Zeros: \", sum(1- predictions_am), \" out of \", n_unlab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
