{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import copy\n",
    "import os\n",
    "\n",
    "### \n",
    "### This includes code copied and pasted from the main methods used for the website in BioKlustering-Website/BioKlustering/mlmodel/parser/spectralClustering.py\n",
    "### These methods are copy-pasted instead of directly included due to difficulties importing Django classes for running locally without running the server\n",
    "###\n",
    "\n",
    "# parseFasta(data) credit to Luke\n",
    "def parseFasta(data):\n",
    "    d = {fasta.id : str(fasta.seq) for fasta in SeqIO.parse(data, \"fasta\")}\n",
    "    pd.DataFrame([d])\n",
    "    s = pd.Series(d, name='Sequence')\n",
    "    s.index.name = 'ID'\n",
    "    s.reset_index()\n",
    "    return pd.DataFrame(s)\n",
    "\n",
    "def get_ids_from_fasta(sequence_paths):\n",
    "    retval = []\n",
    "    for path in sequence_paths:\n",
    "        d = {fasta.id : str(fasta.seq) for fasta in SeqIO.parse(path, \"fasta\")}\n",
    "        retval = np.concatenate((np.array(retval), np.array(list(d.keys()))))\n",
    "    return retval\n",
    "\n",
    "# this method credit to Zhiwen\n",
    "def get_kmer_table(paths,k_min,k_max):\n",
    "    genes,gene_len,output_df = read_fasta(paths)\n",
    "    count_vect = CountVectorizer(analyzer='char', ngram_range=(k_min, k_max))\n",
    "    X = count_vect.fit_transform(genes)\n",
    "    chars = count_vect.get_feature_names_out()\n",
    "    kmers = X.toarray()\n",
    "    kmer_freq = []\n",
    "    for i in range(len(genes)):\n",
    "        kmer_freq.append(kmers[i] / gene_len[i])\n",
    "    input = pd.DataFrame(kmer_freq, columns=chars)\n",
    "    return input, output_df\n",
    "\n",
    "# this method credit to Zhiwen\n",
    "def get_gene_sequences(filename):\n",
    "    genes = []\n",
    "    for record in SeqIO.parse(filename, \"fasta\"):\n",
    "        genes.append(str(record.seq))\n",
    "    return genes\n",
    "\n",
    "# this method credit to Zhiwen\n",
    "# genes: a list of gene sequences, which can directly be generated from get_gene_sequences().\n",
    "def get_gene_len(genes):\n",
    "    gene_len = []\n",
    "\n",
    "    for i in range(len(genes)):\n",
    "        gene_len.append(len(genes[i]))\n",
    "    return gene_len\n",
    "\n",
    "# this method credit to Zhiwen\n",
    "def read_fasta(paths):\n",
    "    all_genes = []\n",
    "    all_gene_len = []\n",
    "    output_df = pd.DataFrame()\n",
    "    \n",
    "    for path in paths:\n",
    "        virus = parseFasta(path)\n",
    "        output_df = pd.concat([output_df, virus])\n",
    "        virus = virus.drop_duplicates(keep=\"last\")\n",
    "        genes_seq = get_gene_sequences(path)\n",
    "        gene_len = get_gene_len(genes_seq)\n",
    "        all_genes = all_genes + genes_seq\n",
    "        all_gene_len = all_gene_len + gene_len\n",
    "    return all_genes,all_gene_len,output_df\n",
    "\n",
    "# this method takes predits the input and make prediction using spectral clustering\n",
    "# paths: a list of strings. contains file paths\n",
    "# k_min: int. min of kmer\n",
    "# k_max: int. max of kmer\n",
    "# num_cluster: int. number of clusters\n",
    "# assignLabels: a string. the way to assign label at the final stage of spectral clustering. Can be \"kmeans\" or \"discretize\"\n",
    "def spectral_clustering(num_cluster, assignLabels, paths, k_min = 2, k_max = 3, seed = 0):\n",
    "    kmer_table, output_df = get_kmer_table(paths, k_min, k_max)\n",
    "    # if len(kmer_table) < num_cluster:\n",
    "    #     raise ValueError()\n",
    "    spectral_clustering = SpectralClustering(n_clusters=num_cluster, assign_labels=assignLabels, random_state=0)\n",
    "    labels = spectral_clustering.fit_predict(kmer_table)\n",
    "    output_df.insert(0, \"Labels\", labels)\n",
    "    return labels,output_df\n",
    "# this method takes prints the spectral clustering result by using PCA\n",
    "# paths: a list of strings. contains file paths\n",
    "# k_min: int. min of kmer\n",
    "# k_max: int. max of kmer\n",
    "# num_cluster: int. number of clusters\n",
    "# assignLabels: a string. the way to assign label at the final stage of spectral clustering. Can be \"kmeans\" or \"discretize\"\n",
    "def PCA_show_spectural_clustering(num_cluster, assignLabels, paths, filename, k_min=2, k_max=3, seed=0):\n",
    "    kmer_table,output_df = get_kmer_table(paths, k_min, k_max);\n",
    "    prediction = SpectralClustering(n_clusters=num_cluster, assign_labels=assignLabels, random_state=seed).fit_predict(\n",
    "        kmer_table)\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(kmer_table)\n",
    "    d = {'dimension1': pca_result[:, 0], 'dimension2': pca_result[:, 1], 'label': prediction}\n",
    "    df = pd.DataFrame(d)\n",
    "    for i in range(num_cluster):\n",
    "        label = df.loc[df['label'] == i]\n",
    "        color = 'C' + str(i)\n",
    "        plt.scatter(label['dimension1'].tolist(), label['dimension2'].tolist(), c=color)\n",
    "    plt.xlabel('principal component 1')\n",
    "    plt.ylabel('principal component 2')\n",
    "    plt.title('Unsupervised Spectral clustring with ' + assignLabels + ' assign label method')\n",
    "    df.to_csv('spectral/' + filename + \"_PCA.csv\")\n",
    "\n",
    "# NOTE: do we also want to show users the optimal k_min and k_max for users here?\n",
    "def intuitive_semi_supervised(num_cluster, file_path, label_path, assignLabels = \"none\", k_min=2, k_max=3, seed=699):\n",
    "    labels = pd.read_csv(label_path)\n",
    "    label_list = labels[\"Labels\"].to_list()\n",
    "    inputlabels = labels[\"Labels\"].to_list()\n",
    "\n",
    "    IDs = get_ids_from_fasta(file_path)\n",
    "    unique_given_labels = get_unique_numbers(label_list)\n",
    "    if num_cluster < len(unique_given_labels) - 1 and -1 in unique_given_labels:\n",
    "        num_cluster = len(unique_given_labels) - 1\n",
    "    if num_cluster < len(unique_given_labels) and -1 not in unique_given_labels:\n",
    "        num_cluster = len(unique_given_labels)\n",
    "    total_len = len(label_list)\n",
    "    unknown_label = -1\n",
    "    total_labeled = 0\n",
    "    optimal_accuracy = 0\n",
    "    optimal_k_min = 0\n",
    "    optimal_k_max = 0\n",
    "    kmer_table = pd.DataFrame(data={})\n",
    "    output_df = pd.DataFrame(data={})\n",
    "    for i in label_list:\n",
    "        if label_list[i] != unknown_label:\n",
    "            total_labeled = total_labeled + 1\n",
    "    res = [0] * total_len\n",
    "    if assignLabels == \"none\":\n",
    "        for i in range(k_min, k_max + 1):\n",
    "            for j in range(i, k_max + 1):\n",
    "                temp_k_min = i\n",
    "                temp_k_max = j\n",
    "                kmer_table, output_df = get_kmer_table(file_path, temp_k_min, temp_k_max)\n",
    "                spectral_clustering = SpectralClustering(n_clusters=num_cluster, assign_labels=\"kmeans\",\n",
    "                                                         random_state=seed)\n",
    "                labels = spectral_clustering.fit_predict(kmer_table)\n",
    "\n",
    "                given_labels_count = {}\n",
    "                labels_list = list(inputlabels)\n",
    "                for label in unique_given_labels:\n",
    "                    given_labels_count[label] = labels_list.count(label)\n",
    "                unique_predicted_labels = get_unique_numbers(labels)\n",
    "                predicted_labels_count = {}\n",
    "                for label in unique_predicted_labels:\n",
    "                    predicted_labels_count[label] = (labels == label).sum()\n",
    "                max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "                if -1 in given_labels_count.keys():\n",
    "                    del given_labels_count[-1]\n",
    "                given_labels_count = sorted(given_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "                predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                unselected_given = copy.deepcopy(unique_given_labels)\n",
    "                if -1 in unselected_given:\n",
    "                    unselected_given.remove(-1)\n",
    "                unselected_pred = copy.deepcopy(unique_predicted_labels)\n",
    "                map_predict_to_actual = {}\n",
    "                for label_GIVEN_dict_entry in given_labels_count:\n",
    "                    label_GIVEN = label_GIVEN_dict_entry[0]\n",
    "                    predicted_labels_count_GIVEN = {}\n",
    "                    label_GIVEN_idx = [index for (index, item) in enumerate(labels_list) if item == label_GIVEN]\n",
    "                    res_GIVEN = [labels[k] for k in label_GIVEN_idx]\n",
    "                    unique_predicted_labels_GIVEN = list(set(get_unique_numbers(res_GIVEN)) & set(unselected_pred))\n",
    "                    if len(unique_predicted_labels_GIVEN) == 0:\n",
    "                        continue\n",
    "                    for lab in unique_predicted_labels_GIVEN:\n",
    "                        predicted_labels_count_GIVEN[lab] = (res_GIVEN == lab).sum()\n",
    "                    map_predict_to_actual[max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get)] = label_GIVEN\n",
    "                    unselected_given.remove(label_GIVEN)\n",
    "                    unselected_pred.remove(max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get))\n",
    "                    \n",
    "                # in the case where multiple given labels completely map to the same \n",
    "                # predicted label, we need to finish assigning given labels to any \n",
    "                # predicted label\n",
    "                for lab_remain in unselected_given:\n",
    "                    for upl in unique_predicted_labels:\n",
    "                        if upl not in map_predict_to_actual.keys():\n",
    "                            map_predict_to_actual[upl] = lab_remain\n",
    "                            unselected_given.remove(lab_remain)\n",
    "                            unselected_pred.remove(upl)\n",
    "                            break\n",
    "\n",
    "\n",
    "                if len(unique_given_labels) <= num_cluster:\n",
    "                    max_value = max(unique_given_labels) + 1\n",
    "                    for upl in unique_predicted_labels:\n",
    "                        if upl not in map_predict_to_actual.keys():\n",
    "                            map_predict_to_actual[upl] = max_value\n",
    "                            max_value += 1\n",
    "                            unselected_pred.remove(upl)\n",
    "                \n",
    "                for l in range(len(unselected_given)):\n",
    "                    map_predict_to_actual[unselected_pred[l]] = unselected_given[l]\n",
    "                    \n",
    "\n",
    "                # predictions_final contains the final results\n",
    "                # it takes care of the case when num_class > number of unique labels given\n",
    "                predictions_tmp = []\n",
    "                for k in range(len(labels)):\n",
    "                    if labels[k] in map_predict_to_actual.keys():\n",
    "                        predictions_tmp.append(map_predict_to_actual[labels[k]])\n",
    "                    else:\n",
    "                        predictions_tmp.append(map_predict_to_actual[max_item])\n",
    "\n",
    "                correct_count = 0\n",
    "                for k in range(len(label_list)):\n",
    "                    if label_list[k] != unknown_label:\n",
    "                        if label_list[k] == predictions_tmp[k]:\n",
    "                            correct_count += 1\n",
    "                temp_accuracy = correct_count / total_labeled\n",
    "                if temp_accuracy > optimal_accuracy:\n",
    "                    optimal_accuracy = temp_accuracy\n",
    "                    optimal_k_min = i\n",
    "                    optimal_k_max = j\n",
    "                    res = labels\n",
    "        for i in range(k_min, k_max + 1):\n",
    "            for j in range(i, k_max + 1):\n",
    "                temp_k_min = i\n",
    "                temp_k_max = j\n",
    "                kmer_table, output_df = get_kmer_table(file_path, temp_k_min, temp_k_max)\n",
    "                spectral_clustering = SpectralClustering(n_clusters=num_cluster, assign_labels=\"discretize\",\n",
    "                                                         random_state=seed)\n",
    "                labels = spectral_clustering.fit_predict(kmer_table)\n",
    "\n",
    "                given_labels_count = {}\n",
    "                labels_list = list(inputlabels)\n",
    "                for label in unique_given_labels:\n",
    "                    given_labels_count[label] = labels_list.count(label)\n",
    "                unique_predicted_labels = get_unique_numbers(labels)\n",
    "                predicted_labels_count = {}\n",
    "                for label in unique_predicted_labels:\n",
    "                    predicted_labels_count[label] = (labels == label).sum()\n",
    "                max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "                if -1 in given_labels_count.keys():\n",
    "                    del given_labels_count[-1]\n",
    "                given_labels_count = sorted(given_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "                predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                unselected_given = copy.deepcopy(unique_given_labels)\n",
    "                if -1 in unselected_given:\n",
    "                    unselected_given.remove(-1)\n",
    "                unselected_pred = copy.deepcopy(unique_predicted_labels)\n",
    "\n",
    "                map_predict_to_actual = {}\n",
    "                for label_GIVEN_dict_entry in given_labels_count:\n",
    "                    label_GIVEN = label_GIVEN_dict_entry[0]\n",
    "                    predicted_labels_count_GIVEN = {}\n",
    "                    label_GIVEN_idx = [index for (index, item) in enumerate(labels_list) if item == label_GIVEN]\n",
    "                    res_GIVEN = [labels[k] for k in label_GIVEN_idx]\n",
    "                    unique_predicted_labels_GIVEN = list(set(get_unique_numbers(res_GIVEN)) & set(unselected_pred))\n",
    "                    if len(unique_predicted_labels_GIVEN) == 0:\n",
    "                        continue\n",
    "                    for lab in unique_predicted_labels_GIVEN:\n",
    "                        predicted_labels_count_GIVEN[lab] = (res_GIVEN == lab).sum()\n",
    "                    map_predict_to_actual[max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get)] = label_GIVEN\n",
    "                    unselected_given.remove(label_GIVEN)\n",
    "                    unselected_pred.remove(max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get))\n",
    "\n",
    "\n",
    "                # in the case where multiple given labels completely map to the same \n",
    "                # predicted label, we need to finish assigning given labels to any \n",
    "                # predicted label\n",
    "                for lab_remain in unselected_given:\n",
    "                    for upl in unique_predicted_labels:\n",
    "                        if upl not in map_predict_to_actual.keys():\n",
    "                            map_predict_to_actual[upl] = lab_remain\n",
    "                            unselected_given.remove(lab_remain)\n",
    "                            unselected_pred.remove(upl)\n",
    "                            break\n",
    "                        \n",
    "                if len(unique_given_labels) <= num_cluster:\n",
    "                    max_value = max(unique_given_labels) + 1\n",
    "                    for upl in unique_predicted_labels:\n",
    "                        if upl not in map_predict_to_actual.keys():\n",
    "                            map_predict_to_actual[upl] = max_value\n",
    "                            max_value += 1\n",
    "                            unselected_pred.remove(upl)\n",
    "                \n",
    "                for l in range(len(unselected_given)):\n",
    "                    map_predict_to_actual[unselected_pred[l]] = unselected_given[l]\n",
    "\n",
    "                # predictions_final contains the final results\n",
    "                # it takes care of the case when num_class > number of unique labels given\n",
    "                predictions_tmp = []\n",
    "                for k in range(len(labels)):\n",
    "                    if labels[k] in map_predict_to_actual.keys():\n",
    "                        predictions_tmp.append(map_predict_to_actual[labels[k]])\n",
    "                    else:\n",
    "                        predictions_tmp.append(map_predict_to_actual[max_item])\n",
    "\n",
    "                correct_count = 0\n",
    "                for k in range(len(label_list)):\n",
    "                    if label_list[k] != unknown_label:\n",
    "                        if label_list[k] == predictions_tmp[k]:\n",
    "                            correct_count += 1\n",
    "                temp_accuracy = correct_count / total_labeled\n",
    "                if temp_accuracy > optimal_accuracy:\n",
    "                    optimal_accuracy = temp_accuracy\n",
    "                    optimal_k_min = i\n",
    "                    optimal_k_max = j\n",
    "                    res = labels\n",
    "\n",
    "    else:\n",
    "        for i in range(k_min, k_max + 1):\n",
    "            for j in range(i, k_max + 1):\n",
    "                temp_k_min = i\n",
    "                temp_k_max = j\n",
    "                kmer_table, output_df = get_kmer_table(file_path, temp_k_min, temp_k_max)\n",
    "                spectral_clustering = SpectralClustering(n_clusters=num_cluster, assign_labels=assignLabels,\n",
    "                                                         random_state=seed)\n",
    "                labels = spectral_clustering.fit_predict(kmer_table)\n",
    "\n",
    "                # Get the counts for the given labels and the predicted labels\n",
    "                given_labels_count = {}\n",
    "                labels_list = list(inputlabels)\n",
    "                for label in unique_given_labels:\n",
    "                    given_labels_count[label] = labels_list.count(label)\n",
    "                unique_predicted_labels = get_unique_numbers(labels)\n",
    "                predicted_labels_count = {}\n",
    "                for label in unique_predicted_labels:\n",
    "                    predicted_labels_count[label] = (labels == label).sum()\n",
    "                max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "                if -1 in given_labels_count.keys():\n",
    "                    del given_labels_count[-1]\n",
    "                given_labels_count = sorted(given_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "                predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                # Map the predicted labels to the given/actual labels\n",
    "                unselected_given = copy.deepcopy(unique_given_labels)\n",
    "                if -1 in unselected_given:\n",
    "                    unselected_given.remove(-1)\n",
    "                unselected_pred = copy.deepcopy(unique_predicted_labels)\n",
    "                \n",
    "                map_predict_to_actual = {}\n",
    "                for label_GIVEN_dict_entry in given_labels_count:\n",
    "                    label_GIVEN = label_GIVEN_dict_entry[0]\n",
    "                    predicted_labels_count_GIVEN = {}\n",
    "                    label_GIVEN_idx = [index for (index, item) in enumerate(labels_list) if item == label_GIVEN]\n",
    "                    res_GIVEN = [labels[k] for k in label_GIVEN_idx]\n",
    "                    unique_predicted_labels_GIVEN = list(set(get_unique_numbers(res_GIVEN)) & set(unselected_pred))\n",
    "                    if len(unique_predicted_labels_GIVEN) == 0:\n",
    "                        continue\n",
    "                    for lab in unique_predicted_labels_GIVEN:\n",
    "                        predicted_labels_count_GIVEN[lab] = (res_GIVEN == lab).sum()\n",
    "                    map_predict_to_actual[max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get)] = label_GIVEN\n",
    "                    unselected_given.remove(label_GIVEN)\n",
    "                    unselected_pred.remove(max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get))\n",
    "\n",
    "                \n",
    "                # in the case where multiple given labels completely map to the same \n",
    "                # predicted label, we need to finish assigning given labels to any \n",
    "                # predicted label\n",
    "                for lab_remain in unselected_given:\n",
    "                    for upl in unique_predicted_labels:\n",
    "                        if upl not in map_predict_to_actual.keys():\n",
    "                            map_predict_to_actual[upl] = lab_remain\n",
    "                            unselected_given.remove(lab_remain)\n",
    "                            unselected_pred.remove(upl)\n",
    "                            break\n",
    "                                        \n",
    "\n",
    "                if len(unique_given_labels) <= num_cluster:\n",
    "                    max_value = max(unique_given_labels) + 1\n",
    "                    for upl in unique_predicted_labels:\n",
    "                        if upl not in map_predict_to_actual.keys():\n",
    "                            map_predict_to_actual[upl] = max_value\n",
    "                            max_value += 1\n",
    "                            unselected_pred.remove(upl)\n",
    "                            \n",
    "                if len(unselected_given) != len(unselected_pred):\n",
    "                    print(\"error: num unselected given =\",len(unselected_given), \"!= unselected pred =\",len(unselected_pred))\n",
    "                    \n",
    "                print(f\"map_predict_to_actual: {map_predict_to_actual}\")\n",
    "            \n",
    "                for l in range(len(unselected_given)):\n",
    "                    map_predict_to_actual[unselected_pred[l]] = unselected_given[l]\n",
    "\n",
    "                # predictions_final contains the final results\n",
    "                # it takes care of the case when num_class > number of unique labels given\n",
    "                predictions_tmp = []\n",
    "                for k in range(len(labels)):\n",
    "                    if labels[k] in map_predict_to_actual.keys():\n",
    "                        predictions_tmp.append(map_predict_to_actual[labels[k]])\n",
    "                    else:\n",
    "                        predictions_tmp.append(map_predict_to_actual[max_item])\n",
    "\n",
    "                correct_count = 0\n",
    "                temp_accuracy = 0\n",
    "                for k in range(len(label_list)):\n",
    "                    if label_list[k] != unknown_label:\n",
    "                        if label_list[k] == predictions_tmp[k]:\n",
    "                            correct_count += 1\n",
    "                temp_accuracy = correct_count / total_labeled\n",
    "                if temp_accuracy > optimal_accuracy:\n",
    "                    optimal_accuracy = temp_accuracy\n",
    "                    optimal_k_min = i\n",
    "                    optimal_k_max = j\n",
    "                    res = labels\n",
    "\n",
    "    res = np.array(res)\n",
    "\n",
    "    # Get the counts for the given labels and the predicted labels\n",
    "    given_labels_count = {}\n",
    "    labels_list = list(inputlabels)\n",
    "    for label in unique_given_labels:\n",
    "        given_labels_count[label] = labels_list.count(label)\n",
    "    unique_predicted_labels = get_unique_numbers(res)\n",
    "    predicted_labels_count = {}\n",
    "    for label in unique_predicted_labels:\n",
    "        predicted_labels_count[label] = (res == label).sum()\n",
    "    max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "    if -1 in given_labels_count.keys():\n",
    "        del given_labels_count[-1]\n",
    "    given_labels_count = sorted(given_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Map the predicted labels to the given/actual labels\n",
    "    unselected_given = copy.deepcopy(unique_given_labels)\n",
    "    if -1 in unselected_given:\n",
    "        unselected_given.remove(-1)\n",
    "    unselected_pred = copy.deepcopy(unique_predicted_labels)\n",
    "\n",
    "    map_predict_to_actual = {}\n",
    "    for label_GIVEN_dict_entry in given_labels_count:\n",
    "        label_GIVEN = label_GIVEN_dict_entry[0]\n",
    "        predicted_labels_count_GIVEN = {}\n",
    "        label_GIVEN_idx = [index for (index, item) in enumerate(labels_list) if item == label_GIVEN]\n",
    "        res_GIVEN = [res[k] for k in label_GIVEN_idx]\n",
    "        unique_predicted_labels_GIVEN = list(set(get_unique_numbers(res_GIVEN)) & set(unselected_pred))\n",
    "        if len(unique_predicted_labels_GIVEN) == 0:\n",
    "            continue\n",
    "        for lab in unique_predicted_labels_GIVEN:\n",
    "            predicted_labels_count_GIVEN[lab] = (res_GIVEN == lab).sum()\n",
    "        map_predict_to_actual[max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get)] = label_GIVEN\n",
    "        unselected_given.remove(label_GIVEN)\n",
    "        unselected_pred.remove(max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get))\n",
    "\n",
    "\n",
    "    # in the case where multiple given labels completely map to the same \n",
    "    # predicted label, we need to finish assigning given labels to any \n",
    "    # predicted label\n",
    "    for lab_remain in unselected_given:\n",
    "        for upl in unique_predicted_labels:\n",
    "            if upl not in map_predict_to_actual.keys():\n",
    "                map_predict_to_actual[upl] = lab_remain\n",
    "                unselected_given.remove(lab_remain)\n",
    "                unselected_pred.remove(upl)\n",
    "                break\n",
    "            \n",
    "    if len(unique_given_labels) <= num_cluster:\n",
    "        max_value = max(unique_given_labels) + 1\n",
    "        for upl in unique_predicted_labels:\n",
    "            if upl not in map_predict_to_actual.keys():\n",
    "                # print(f\"{upl} mapped to {max_value}\")\n",
    "                map_predict_to_actual[upl] = max_value\n",
    "                max_value += 1\n",
    "                unselected_pred.remove(upl)\n",
    "    \n",
    "    if len(unselected_given) != len(unselected_pred):\n",
    "        print(\"error: num unselected given =\",len(unselected_given), \"!= unselected pred =\",len(unselected_pred))\n",
    "        \n",
    "    print(f\"map_predict_to_actual: {map_predict_to_actual}\")\n",
    "    \n",
    "    for l in range(len(unselected_given)):\n",
    "        map_predict_to_actual[unselected_pred[l]] = unselected_given[l]\n",
    "\n",
    "\n",
    "    # predictions_final contains the final results\n",
    "    # it takes care of the case when num_class > number of unique labels given\n",
    "    predictions_final = []\n",
    "    predictions_tmp = []\n",
    "    for i in range(len(res)):\n",
    "        if inputlabels[i] == -1:\n",
    "            if res[i] in map_predict_to_actual.keys():\n",
    "                predictions_final.append(map_predict_to_actual[res[i]])\n",
    "            else:\n",
    "                predictions_final.append(map_predict_to_actual[max_item])\n",
    "        else:\n",
    "            predictions_final.append(inputlabels[i])\n",
    "        if res[i] in map_predict_to_actual.keys():\n",
    "            predictions_tmp.append(map_predict_to_actual[res[i]])\n",
    "        else:\n",
    "            predictions_tmp.append(map_predict_to_actual[max_item])\n",
    "    res = np.array(predictions_final) \n",
    "    \n",
    "    return res, np.array(predictions_tmp)\n",
    "    \n",
    "def PCA_show_semi_spectural_clustering(num_cluster, file_path, label_path, filename, assignLabels = \"none\", k_min=2, k_max=3, seed=699):\n",
    "    prediction,_ = intuitive_semi_supervised(num_cluster,  file_path, label_path, assignLabels, k_min, k_max, seed)\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(kmer_table)\n",
    "    d = {'dimension1': pca_result[:, 0], 'dimension2': pca_result[:, 1], 'label': prediction}\n",
    "    df = pd.DataFrame(d)\n",
    "    for i in range(num_cluster):\n",
    "        label = df.loc[df['label'] == i]\n",
    "        color = 'C' + str(i)\n",
    "        plt.scatter(label['dimension1'].tolist(), label['dimension2'].tolist(), c=color)\n",
    "    plt.xlabel('principal component 1')\n",
    "    plt.ylabel('principal component 2')\n",
    "    plt.title('Semi-supervised Spectral clustring with ' + assignLabels + ' assign label method')\n",
    "    df.to_csv('spectral/' + filename + \"_PCA.csv\")\n",
    "\n",
    "def get_unique_numbers(numbers):\n",
    "\n",
    "    list_of_unique_numbers = []\n",
    "\n",
    "    unique_numbers = set(numbers)\n",
    "\n",
    "    for number in unique_numbers:\n",
    "        list_of_unique_numbers.append(number)\n",
    "\n",
    "    return list_of_unique_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nucleotide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map_predict_to_actual: {1: 0, 0: 1}\n"
     ]
    }
   ],
   "source": [
    "path = [\"../combined_nucleotide.fasta\"]\n",
    "lab_path = \"../combined_labels_nucleotide.csv\"\n",
    "k_min = 2\n",
    "k_max = 3\n",
    "num_classes = 2\n",
    "seed = 32624\n",
    "predictions_nuc, tmp = intuitive_semi_supervised(num_classes,path,lab_path,\"none\",k_min,k_max,seed)\n",
    "\n",
    "kmer_table,output_df = get_kmer_table(path, k_min, k_max)\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(kmer_table)\n",
    "d = {'ID': pd.Series(output_df.index), 'principal component 1': pca_result[:, 0], 'principal component 2': pca_result[:, 1], 'label': predictions_nuc}\n",
    "finalDf = pd.DataFrame(d)\n",
    "finalDf.columns = ['ID','principal Component 1', 'principal Component 2','label']\n",
    "finalDf.to_csv('../results/nuc_spectral_pca.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones:  207  out of  350\n",
      "Zeros:  159  out of  350\n"
     ]
    }
   ],
   "source": [
    "labels_nuc = pd.Series(pd.read_csv(\"../combined_labels_nucleotide.csv\").Labels)\n",
    "n_unlab = sum(labels_nuc == -1)\n",
    "\n",
    "print(\"Ones: \", sum(predictions_nuc), \" out of \", n_unlab)\n",
    "print(\"Zeros: \", sum(1- predictions_nuc), \" out of \", n_unlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amino Acids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map_predict_to_actual: {0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "path = [\"../combined_amino.fasta\"]\n",
    "lab_path = \"../combined_labels_amino.csv\"\n",
    "k_min = 4\n",
    "k_max = 5\n",
    "num_classes = 2\n",
    "seed = 32624\n",
    "predictions_am, tmp = intuitive_semi_supervised(num_classes,path,lab_path,\"none\",k_min,k_max,seed)\n",
    "\n",
    "kmer_table,output_df = get_kmer_table(path, k_min, k_max)\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(kmer_table)\n",
    "d = {'ID': pd.Series(output_df.index), 'principal component 1': pca_result[:, 0], 'principal component 2': pca_result[:, 1], 'label': predictions_am}\n",
    "finalDf = pd.DataFrame(d)\n",
    "finalDf.columns = ['ID','principal Component 1', 'principal Component 2','label']\n",
    "finalDf.to_csv('../results/am_spectral_pca.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones:  8  out of  465\n",
      "Zeros:  473  out of  465\n"
     ]
    }
   ],
   "source": [
    "labels_am = pd.Series(pd.read_csv(\"../combined_labels_amino.csv\").Labels)\n",
    "n_unlab = sum(labels_am == -1)\n",
    "\n",
    "print(\"Ones: \", sum(predictions_am), \" out of \", n_unlab)\n",
    "print(\"Zeros: \", sum(1- predictions_am), \" out of \", n_unlab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
