{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "### This includes code copied and pasted from the main methods used for the website in BioKlustering-Website/BioKlustering/mlmodel/parser/spectralClustering.py\n",
    "### These methods are copy-pasted instead of directly included due to difficulties importing Django classes for running locally without running the server\n",
    "###\n",
    "\n",
    "# parseFasta(data) credit to Luke\n",
    "def parseFasta(data):\n",
    "    d = {fasta.id : str(fasta.seq) for fasta in SeqIO.parse(data, \"fasta\")}\n",
    "    pd.DataFrame([d])\n",
    "    s = pd.Series(d, name='Sequence')\n",
    "    s.index.name = 'ID'\n",
    "    s.reset_index()\n",
    "    return pd.DataFrame(s)\n",
    "\n",
    "# this method credit to Zhiwen\n",
    "def get_kmer_table(paths,k_min,k_max):\n",
    "    genes,gene_len,output_df = read_fasta(paths)\n",
    "    count_vect = CountVectorizer(analyzer='char', ngram_range=(k_min, k_max))\n",
    "    X = count_vect.fit_transform(genes)\n",
    "    chars = count_vect.get_feature_names_out()\n",
    "    kmers = X.toarray()\n",
    "    kmer_freq = []\n",
    "    for i in range(len(genes)):\n",
    "        kmer_freq.append(kmers[i] / gene_len[i])\n",
    "    input = pd.DataFrame(kmer_freq, columns=chars)\n",
    "    return input, output_df\n",
    "\n",
    "# this method credit to Zhiwen\n",
    "def get_gene_sequences(filename):\n",
    "    genes = []\n",
    "    for record in SeqIO.parse(filename, \"fasta\"):\n",
    "        genes.append(str(record.seq))\n",
    "    return genes\n",
    "\n",
    "# this method credit to Zhiwen\n",
    "# genes: a list of gene sequences, which can directly be generated from get_gene_sequences().\n",
    "def get_gene_len(genes):\n",
    "    gene_len = []\n",
    "\n",
    "    for i in range(len(genes)):\n",
    "        gene_len.append(len(genes[i]))\n",
    "    return gene_len\n",
    "\n",
    "# this method credit to Zhiwen\n",
    "def read_fasta(paths):\n",
    "    all_genes = []\n",
    "    all_gene_len = []\n",
    "    output_df = pd.DataFrame()\n",
    "    \n",
    "    for path in paths:\n",
    "        virus = parseFasta(path)\n",
    "        output_df = pd.concat([output_df, virus])\n",
    "        virus = virus.drop_duplicates(keep=\"last\")\n",
    "        genes_seq = get_gene_sequences(path)\n",
    "        gene_len = get_gene_len(genes_seq)\n",
    "        all_genes = all_genes + genes_seq\n",
    "        all_gene_len = all_gene_len + gene_len\n",
    "    return all_genes,all_gene_len,output_df\n",
    "\n",
    "# this method takes predits the input and make prediction using spectral clustering\n",
    "# paths: a list of strings. contains file paths\n",
    "# k_min: int. min of kmer\n",
    "# k_max: int. max of kmer\n",
    "# num_cluster: int. number of clusters\n",
    "# assignLabels: a string. the way to assign label at the final stage of spectral clustering. Can be \"kmeans\" or \"discretize\"\n",
    "def spectral_clustering(num_cluster, assignLabels, paths, k_min = 2, k_max = 3, seed = 0):\n",
    "    kmer_table, output_df = get_kmer_table(paths, k_min, k_max)\n",
    "    # if len(kmer_table) < num_cluster:\n",
    "    #     raise ValueError()\n",
    "    spectral_clustering = SpectralClustering(n_clusters=num_cluster, assign_labels=assignLabels, random_state=0)\n",
    "    labels = spectral_clustering.fit_predict(kmer_table)\n",
    "    output_df.insert(0, \"Labels\", labels)\n",
    "    return labels,output_df\n",
    "\n",
    "\n",
    "def intuitive_semi_supervised(num_cluster, file_path, label_path, assignLabels = \"none\", k_min=2, k_max=3, seed=699):\n",
    "    labels = pd.read_csv(label_path)\n",
    "    label_list = labels[\"Labels\"].to_list()\n",
    "    inputlabels = labels[\"Labels\"].to_list()\n",
    "\n",
    "    #print(label_list)\n",
    "\n",
    "    unique_given_labels = get_unique_numbers(label_list)\n",
    "    if num_cluster < len(unique_given_labels) - 1 and -1 in unique_given_labels:\n",
    "        num_cluster = len(unique_given_labels) - 1\n",
    "    if num_cluster < len(unique_given_labels) and -1 not in unique_given_labels:\n",
    "        num_cluster = len(unique_given_labels)\n",
    "    total_len = len(label_list)\n",
    "    print(total_len)\n",
    "    unknown_label = -1\n",
    "    total_labeled = 0\n",
    "    optimal_accuracy = 0\n",
    "    optimal_k_min = 0\n",
    "    optimal_k_max = 0\n",
    "    for i in label_list:\n",
    "        if i != unknown_label:\n",
    "            total_labeled = total_labeled + 1\n",
    "    res = [0] * total_len\n",
    "    \n",
    "    if (assignLabels == \"none\"):\n",
    "        \n",
    "        for i in range(k_min, k_max + 1):\n",
    "            for j in range(i, k_max + 1):\n",
    "                temp_k_min = i\n",
    "                temp_k_max = j\n",
    "                kmer_table,output_df = get_kmer_table(file_path, temp_k_min, temp_k_max)\n",
    "                spectral_clustering = SpectralClustering(n_clusters=num_cluster, assign_labels=\"kmeans\",\n",
    "                                                     random_state=seed)\n",
    "                labels = spectral_clustering.fit_predict(kmer_table)\n",
    "\n",
    "                given_labels_count = {}\n",
    "                labels_list = list(inputlabels)\n",
    "                for label in unique_given_labels:\n",
    "                    given_labels_count[label] = labels_list.count(label)\n",
    "                unique_predicted_labels = get_unique_numbers(labels)\n",
    "                predicted_labels_count = {}\n",
    "                for label in unique_predicted_labels:\n",
    "                    predicted_labels_count[label] = (labels == label).sum()\n",
    "                max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "                if -1 in given_labels_count.keys():\n",
    "                    del given_labels_count[-1]\n",
    "                given_labels_count = sorted(given_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "                predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                unselected_given = copy.deepcopy(unique_given_labels)\n",
    "                if -1 in unselected_given:\n",
    "                    unselected_given.remove(-1)\n",
    "                unselected_pred = copy.deepcopy(unique_predicted_labels)\n",
    "                map_predict_to_actual = {}\n",
    "                for label_GIVEN_dict_entry in given_labels_count:\n",
    "                    label_GIVEN = label_GIVEN_dict_entry[0]\n",
    "                    predicted_labels_count_GIVEN = {}\n",
    "                    label_GIVEN_idx = [index for (index, item) in enumerate(labels_list) if item == label_GIVEN]\n",
    "                    res_GIVEN = [labels[k] for k in label_GIVEN_idx]\n",
    "                    #print(res_GIVEN)\n",
    "                    unique_predicted_labels_GIVEN = list(set(get_unique_numbers(res_GIVEN)) & set(unselected_pred))\n",
    "                    if len(unique_predicted_labels_GIVEN) == 0:\n",
    "                        continue\n",
    "                    for lab in unique_predicted_labels_GIVEN:\n",
    "                        predicted_labels_count_GIVEN[lab] = (res_GIVEN == lab).sum()\n",
    "                    map_predict_to_actual[max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get)] = label_GIVEN\n",
    "                    unselected_given.remove(label_GIVEN)\n",
    "                    unselected_pred.remove(max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get))\n",
    "\n",
    "\n",
    "                if len(unique_given_labels) <= num_cluster:\n",
    "                    max_value = max(unique_given_labels) + 1\n",
    "                    for upl in unique_predicted_labels:\n",
    "                        if upl not in map_predict_to_actual.keys():\n",
    "                            map_predict_to_actual[upl] = max_value\n",
    "                            max_value += 1\n",
    "                            unselected_pred.remove(upl)\n",
    "                \n",
    "                for l in range(len(unselected_given)):\n",
    "                    map_predict_to_actual[unselected_pred[l]] = unselected_given[l]\n",
    "                    \n",
    "\n",
    "                # predictions_final contains the final results\n",
    "                # it takes care of the case when num_class > number of unique labels given\n",
    "                predictions_tmp = []\n",
    "                for k in range(len(labels)):\n",
    "                    if labels[k] in map_predict_to_actual.keys():\n",
    "                        predictions_tmp.append(map_predict_to_actual[labels[k]])\n",
    "                    else:\n",
    "                        predictions_tmp.append(map_predict_to_actual[max_item])\n",
    "\n",
    "                correct_count = 0\n",
    "                temp_accuracy = 0\n",
    "                for k in range(len(label_list)):\n",
    "                    if (label_list[k] != unknown_label):\n",
    "                        if (label_list[k] == predictions_tmp[k]):\n",
    "                            correct_count += 1\n",
    "                temp_accuracy = correct_count / total_labeled\n",
    "                if (temp_accuracy > optimal_accuracy):\n",
    "                    optimal_accuracy = temp_accuracy\n",
    "                    optimal_k_min = i\n",
    "                    optimal_k_max = j\n",
    "                    res = labels\n",
    "                \n",
    "        for i in range(k_min, k_max + 1):\n",
    "            for j in range(i, k_max + 1):\n",
    "                temp_k_min = i\n",
    "                temp_k_max = j\n",
    "                kmer_table,output_df = get_kmer_table(file_path, temp_k_min, temp_k_max)\n",
    "                spectral_clustering = SpectralClustering(n_clusters=num_cluster, assign_labels=\"discretize\",\n",
    "                                                     random_state=seed)\n",
    "                labels = spectral_clustering.fit_predict(kmer_table)\n",
    "\n",
    "                given_labels_count = {}\n",
    "                labels_list = list(inputlabels)\n",
    "                for label in unique_given_labels:\n",
    "                    given_labels_count[label] = labels_list.count(label)\n",
    "                unique_predicted_labels = get_unique_numbers(labels)\n",
    "                predicted_labels_count = {}\n",
    "                for label in unique_predicted_labels:\n",
    "                    predicted_labels_count[label] = (labels == label).sum()\n",
    "                max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "                if -1 in given_labels_count.keys():\n",
    "                    del given_labels_count[-1]\n",
    "                given_labels_count = sorted(given_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "                predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                unselected_given = copy.deepcopy(unique_given_labels)\n",
    "                if -1 in unselected_given:\n",
    "                    unselected_given.remove(-1)\n",
    "                unselected_pred = copy.deepcopy(unique_predicted_labels)\n",
    "\n",
    "                map_predict_to_actual = {}\n",
    "                for label_GIVEN_dict_entry in given_labels_count:\n",
    "                    label_GIVEN = label_GIVEN_dict_entry[0]\n",
    "                    predicted_labels_count_GIVEN = {}\n",
    "                    label_GIVEN_idx = [index for (index, item) in enumerate(labels_list) if item == label_GIVEN]\n",
    "                    res_GIVEN = [labels[k] for k in label_GIVEN_idx]\n",
    "                    unique_predicted_labels_GIVEN = list(set(get_unique_numbers(res_GIVEN)) & set(unselected_pred))\n",
    "                    if len(unique_predicted_labels_GIVEN) == 0:\n",
    "                        continue\n",
    "                    for lab in unique_predicted_labels_GIVEN:\n",
    "                        predicted_labels_count_GIVEN[lab] = (res_GIVEN == lab).sum()\n",
    "                    map_predict_to_actual[max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get)] = label_GIVEN\n",
    "                    unselected_given.remove(label_GIVEN)\n",
    "                    unselected_pred.remove(max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get))\n",
    "\n",
    "\n",
    "                if len(unique_given_labels) <= num_cluster:\n",
    "                    max_value = max(unique_given_labels) + 1\n",
    "                    for upl in unique_predicted_labels:\n",
    "                        if upl not in map_predict_to_actual.keys():\n",
    "                            print(f\"{upl} mapped to {max_value}\")\n",
    "                            map_predict_to_actual[upl] = max_value\n",
    "                            max_value += 1\n",
    "                            unselected_pred.remove(upl)\n",
    "                \n",
    "                for l in range(len(unselected_given)):\n",
    "                    map_predict_to_actual[unselected_pred[l]] = unselected_given[l]\n",
    "\n",
    "                # predictions_final contains the final results\n",
    "                # it takes care of the case when num_class > number of unique labels given\n",
    "                predictions_tmp = []\n",
    "                for k in range(len(labels)):\n",
    "                    if labels[k] in map_predict_to_actual.keys():\n",
    "                        predictions_tmp.append(map_predict_to_actual[labels[k]])\n",
    "                    else:\n",
    "                        predictions_tmp.append(map_predict_to_actual[max_item])\n",
    "\n",
    "                correct_count = 0\n",
    "                temp_accuracy = 0\n",
    "                for k in range(len(label_list)):\n",
    "                    if (label_list[k] != unknown_label):\n",
    "                        if (label_list[k] == predictions_tmp[k]):\n",
    "                            correct_count += 1\n",
    "                temp_accuracy = correct_count / total_labeled\n",
    "                if (temp_accuracy > optimal_accuracy):\n",
    "                    optimal_accuracy = temp_accuracy\n",
    "                    optimal_k_min = i\n",
    "                    optimal_k_max = j\n",
    "                    res = labels\n",
    "        print(\"The optimal accuracy based on labeled sequences is: \" + str(optimal_accuracy))\n",
    "        print(\"The optimal k_min is: \" + str(optimal_k_min))\n",
    "        print(\"The optimal k_max is: \" + str(optimal_k_max))\n",
    "\n",
    "        res = np.array(res)\n",
    "    else:\n",
    "        for i in range(k_min, k_max + 1):\n",
    "            for j in range(i, k_max + 1):\n",
    "                temp_k_min = i\n",
    "                temp_k_max = j\n",
    "                kmer_table,output_df = get_kmer_table(file_path, temp_k_min, temp_k_max)\n",
    "                spectral_clustering = SpectralClustering(n_clusters=num_cluster, assign_labels=assignLabels,\n",
    "                                                     random_state=seed)\n",
    "                labels = spectral_clustering.fit_predict(kmer_table)\n",
    "                # Get the counts for the given labels and the predicted labels\n",
    "                given_labels_count = {}\n",
    "                labels_list = list(inputlabels)\n",
    "                for label in unique_given_labels:\n",
    "                    given_labels_count[label] = labels_list.count(label)\n",
    "                unique_predicted_labels = get_unique_numbers(labels)\n",
    "                predicted_labels_count = {}\n",
    "                for label in unique_predicted_labels:\n",
    "                    predicted_labels_count[label] = (labels == label).sum()\n",
    "                max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "                if -1 in given_labels_count.keys():\n",
    "                    del given_labels_count[-1]\n",
    "                given_labels_count = sorted(given_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "                predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                # Map the predicted labels to the given/actual labels\n",
    "                unselected_given = copy.deepcopy(unique_given_labels)\n",
    "                if -1 in unselected_given:\n",
    "                    unselected_given.remove(-1)\n",
    "                unselected_pred = copy.deepcopy(unique_predicted_labels)\n",
    "\n",
    "                map_predict_to_actual = {}\n",
    "                for label_GIVEN_dict_entry in given_labels_count:\n",
    "                    label_GIVEN = label_GIVEN_dict_entry[0]\n",
    "                    predicted_labels_count_GIVEN = {}\n",
    "                    label_GIVEN_idx = [index for (index, item) in enumerate(labels_list) if item == label_GIVEN]\n",
    "                    res_GIVEN = [labels[k] for k in label_GIVEN_idx]\n",
    "                    unique_predicted_labels_GIVEN = list(set(get_unique_numbers(res_GIVEN)) & set(unselected_pred))\n",
    "                    if len(unique_predicted_labels_GIVEN) == 0:\n",
    "                        continue\n",
    "                    for lab in unique_predicted_labels_GIVEN:\n",
    "                        predicted_labels_count_GIVEN[lab] = (res_GIVEN == lab).sum()\n",
    "                    map_predict_to_actual[max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get)] = label_GIVEN\n",
    "                    unselected_given.remove(label_GIVEN)\n",
    "                    unselected_pred.remove(max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get))\n",
    "\n",
    "\n",
    "                if len(unique_given_labels) <= num_cluster:\n",
    "                    max_value = max(unique_given_labels) + 1\n",
    "                    for upl in unique_predicted_labels:\n",
    "                        if upl not in map_predict_to_actual.keys():\n",
    "                            print(f\"{upl} mapped to {max_value}\")\n",
    "                            map_predict_to_actual[upl] = max_value\n",
    "                            max_value += 1\n",
    "                            unselected_pred.remove(upl)\n",
    "            \n",
    "                for l in range(len(unselected_given)):\n",
    "                    map_predict_to_actual[unselected_pred[l]] = unselected_given[l]\n",
    "\n",
    "                # predictions_final contains the final results\n",
    "                # it takes care of the case when num_class > number of unique labels given\n",
    "                predictions_tmp = []\n",
    "                for k in range(len(labels)):\n",
    "                    if labels[k] in map_predict_to_actual.keys():\n",
    "                        predictions_tmp.append(map_predict_to_actual[labels[k]])\n",
    "                    else:\n",
    "                        predictions_tmp.append(map_predict_to_actual[max_item])\n",
    "\n",
    "                correct_count = 0\n",
    "                temp_accuracy = 0\n",
    "                for k in range(len(label_list)):\n",
    "                    if (label_list[k] != unknown_label):\n",
    "                        if (label_list[k] == predictions_tmp[k]):\n",
    "                            correct_count += 1\n",
    "                temp_accuracy = correct_count / total_labeled\n",
    "                if (temp_accuracy > optimal_accuracy):\n",
    "                    optimal_accuracy = temp_accuracy\n",
    "                    optimal_k_min = i\n",
    "                    optimal_k_max = j\n",
    "                    res = labels\n",
    "        print(\"The optimal accuracy based on labeled sequences is: \" + str(optimal_accuracy))\n",
    "        print(\"The optimal k_min is: \" + str(optimal_k_min))\n",
    "        print(\"The optimal k_max is: \" + str(optimal_k_max))\n",
    "\n",
    "        res = np.array(res)\n",
    "\n",
    "    labels = pd.read_csv(label_path)\n",
    "    inputlabels = labels[\"Labels\"].to_list()\n",
    "\n",
    "    # Get the counts for the given labels and the predicted labels\n",
    "    given_labels_count = {}\n",
    "    labels_list = list(inputlabels)\n",
    "    for label in unique_given_labels:\n",
    "        given_labels_count[label] = labels_list.count(label)\n",
    "    unique_predicted_labels = get_unique_numbers(res)\n",
    "    predicted_labels_count = {}\n",
    "    for label in unique_predicted_labels:\n",
    "        predicted_labels_count[label] = (res == label).sum()\n",
    "    max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "    if -1 in given_labels_count.keys():\n",
    "        del given_labels_count[-1]\n",
    "    given_labels_count = sorted(given_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Map the predicted labels to the given/actual labels\n",
    "    unselected_given = copy.deepcopy(unique_given_labels)\n",
    "    if -1 in unselected_given:\n",
    "        unselected_given.remove(-1)\n",
    "    unselected_pred = copy.deepcopy(unique_predicted_labels)\n",
    "    map_predict_to_actual = {}\n",
    "    for label_GIVEN_dict_entry in given_labels_count:\n",
    "        label_GIVEN = label_GIVEN_dict_entry[0]\n",
    "        predicted_labels_count_GIVEN = {}\n",
    "        label_GIVEN_idx = [index for (index, item) in enumerate(labels_list) if item == label_GIVEN]\n",
    "        res_GIVEN = [res[k] for k in label_GIVEN_idx]\n",
    "        unique_predicted_labels_GIVEN = list(set(get_unique_numbers(res_GIVEN)) & set(unselected_pred))\n",
    "        if len(unique_predicted_labels_GIVEN) == 0:\n",
    "            continue\n",
    "        for lab in unique_predicted_labels_GIVEN:\n",
    "            predicted_labels_count_GIVEN[lab] = (res_GIVEN == lab).sum()\n",
    "        map_predict_to_actual[max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get)] = label_GIVEN\n",
    "        unselected_given.remove(label_GIVEN)\n",
    "        unselected_pred.remove(max(predicted_labels_count_GIVEN, key=predicted_labels_count_GIVEN.get))\n",
    "\n",
    "\n",
    "    if len(unique_given_labels) <= num_cluster:\n",
    "        max_value = max(unique_given_labels) + 1\n",
    "        for upl in unique_predicted_labels:\n",
    "            if upl not in map_predict_to_actual.keys():\n",
    "                print(f\"{upl} mapped to {max_value}\")\n",
    "                map_predict_to_actual[upl] = max_value\n",
    "                max_value += 1\n",
    "                unselected_pred.remove(upl)\n",
    "    \n",
    "    if len(unselected_given) != len(unselected_pred):\n",
    "        print(\"error: num unselected given =\",len(unselected_given), \"!= unselected pred =\",len(unselected_pred))\n",
    "    \n",
    "    #for l in range(len(unselected_given)):\n",
    "    #    map_predict_to_actual[unselected_pred[l]] = unselected_given[l]\n",
    "    \n",
    "    \n",
    "    print(f\"map_predict_to_actual: {map_predict_to_actual}\")\n",
    "\n",
    "    # predictions_final contains the final results\n",
    "    # it takes care of the case when num_class > number of unique labels given\n",
    "    predictions_final = []\n",
    "    predictions_tmp = []\n",
    "    for i in range(len(res)):\n",
    "        if inputlabels[i] == -1:\n",
    "            if res[i] in map_predict_to_actual.keys():\n",
    "                predictions_final.append(map_predict_to_actual[res[i]])\n",
    "            else:\n",
    "                predictions_final.append(map_predict_to_actual[max_item])\n",
    "        else:\n",
    "            predictions_final.append(inputlabels[i])\n",
    "        if res[i] in map_predict_to_actual.keys():\n",
    "            predictions_tmp.append(map_predict_to_actual[res[i]])\n",
    "        else:\n",
    "            predictions_tmp.append(map_predict_to_actual[max_item])\n",
    "    res = np.array(predictions_final) \n",
    "\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_unique_numbers(numbers):\n",
    "\n",
    "    list_of_unique_numbers = []\n",
    "\n",
    "    unique_numbers = set(numbers)\n",
    "\n",
    "    for number in unique_numbers:\n",
    "        list_of_unique_numbers.append(number)\n",
    "\n",
    "    return list_of_unique_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta = [\"concatenated.fasta\"]\n",
    "\n",
    "# Define the actual labels\n",
    "actual_labels = pd.read_csv(\"./responses-carb.csv\")\n",
    "actual_labels = actual_labels[\"class\"]\n",
    "actual_labels = actual_labels.tolist()\n",
    "\n",
    "k_min = 3\n",
    "k_max = 3\n",
    "cNum = len(np.unique(actual_labels))\n",
    "predictions1, x = spectral_clustering(cNum, \"kmeans\", fasta, k_min, k_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Matching': {0: 1, 1: 0}, 'Accuracy': 0.7131147540983607}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def get_accuracy(predicted_labels, actual_labels):\n",
    "    # Generate all possible permutations of label mappings\n",
    "    possible_mappings = list(itertools.permutations(set(predicted_labels)))\n",
    "\n",
    "    # Function to calculate accuracy given a label mapping\n",
    "    def calculate_accuracy(actual_labels, predicted_labels, mapping):\n",
    "        mapped_labels = [mapping[label] for label in predicted_labels]\n",
    "        correct_predictions = sum(1 for actual, predicted in zip(actual_labels, mapped_labels) if actual == predicted)\n",
    "        return correct_predictions / len(actual_labels)\n",
    "\n",
    "    # Find the mapping with the highest accuracy\n",
    "    best_mapping = None\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for mapping in possible_mappings:\n",
    "        accuracy = calculate_accuracy(actual_labels, predicted_labels, mapping)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_mapping = mapping\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "    # Create a dictionary containing the best matching and accuracy\n",
    "    matching_results = {\n",
    "        'Matching': dict(zip(set(predicted_labels), best_mapping)),\n",
    "        'Accuracy': best_accuracy\n",
    "    }\n",
    "\n",
    "    # Print the results\n",
    "    return matching_results\n",
    "\n",
    "best_mapping = get_accuracy(predictions1, actual_labels)\n",
    "print(best_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = [best_mapping['Matching'][label] for label in predictions1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_label = pd.read_csv(\"./responses-carb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = list(range(1, len(predictions1)+1))\n",
    "df = pd.DataFrame(list(zip(number, predictions1)), \n",
    "               columns =['Number', 'Labels']) \n",
    "df.to_csv('spectral_unsup_predictions.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_kmer_table(fasta, k_min, k_max)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents,columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([principalDf, pd.Series(predictions1)], axis = 1)\n",
    "finalDf = pd.concat([finalDf, pd.Series(actual_label['class'])], axis = 1)\n",
    "finalDf.columns = ['principal Component 1', 'Principal Component 2','Predicted Label', 'Actual Label']\n",
    "finalDf.to_csv('spectral_unsup_pca.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7131147540983607"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(finalDf['Predicted Label'] == finalDf['Actual Label'])/len(finalDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "The optimal accuracy based on labeled sequences is: 0.7692307692307693\n",
      "The optimal k_min is: 10\n",
      "The optimal k_max is: 10\n",
      "map_predict_to_actual: {1: 0, 0: 1}\n",
      "[1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1\n",
      " 0 0 0 1 0 1 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "new_paths = [\"concatenated.fasta\"]\n",
    "\n",
    "semi_labels = pd.read_csv(\"./carb-semi-labels.csv\")\n",
    "semi_labels = pd.Series(semi_labels['Labels'])\n",
    "\n",
    "actual_labels = pd.read_csv(\"./responses-carb.csv\")\n",
    "actual_labels = actual_labels[\"class\"]\n",
    "actual_labels = actual_labels.tolist()\n",
    "\n",
    "k_min = 3\n",
    "k_max = 3\n",
    "\n",
    "num_class = 2\n",
    "\n",
    "predictions2 = intuitive_semi_supervised(num_class,new_paths,\"carb-semi-labels.csv\",\"discretize\",k_min,k_max)\n",
    "\n",
    "print(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = list(range(1, len(predictions2)+1))\n",
    "df = pd.DataFrame(list(zip(number, predictions2)), \n",
    "               columns =['Number', 'Labels']) \n",
    "df.to_csv('spectral_semisup_predictions.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
