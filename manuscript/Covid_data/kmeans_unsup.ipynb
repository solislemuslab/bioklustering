{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn import preprocessing \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "### \n",
    "### This includes code copied and pasted from the main methods used for the website in BioKlustering-Website/BioKlustering/mlmodel/parser/kmeans.py\n",
    "### These methods are copy-pasted instead of directly included due to difficulties importing Django classes for running locally without running the server\n",
    "###\n",
    "\n",
    "def parseFasta(data):\n",
    "    d = {fasta.id : str(fasta.seq) for fasta in SeqIO.parse(data, \"fasta\")}\n",
    "    pd.DataFrame([d])\n",
    "\n",
    "    s = pd.Series(d, name='Sequence')\n",
    "    s.index.name = 'ID'\n",
    "    s.reset_index()\n",
    "    return pd.DataFrame(s)\n",
    "\n",
    "def kmerXTable(s, a, b):\n",
    "    tfid_vector = TfidfVectorizer(analyzer='char', ngram_range=(a,b))\n",
    "    s_hat = tfid_vector.fit_transform(s.Sequence)\n",
    "    kmerNames = tfid_vector.get_feature_names()\n",
    "    kmers = s_hat.toarray()\n",
    "    return pd.DataFrame(kmers,columns=kmerNames, index = s.index)\n",
    "    \n",
    "def kmeans(fasta, cNum, klength_min = 6, klength_max = 6, rNum = 50):\n",
    "    inputData = parseFasta(fasta)\n",
    "#     temp = virus01.append(inputData)\n",
    "#     temp = temp.drop_duplicates(keep=\"last\")\n",
    "        \n",
    "    inputData[\"Sequence\"] = inputData[\"Sequence\"].apply(lambda x: x.replace(\"-\", \"\"))\n",
    "    kmerXTableInput = kmerXTable(inputData, klength_min, klength_max)\n",
    "        \n",
    "        \n",
    "    #km = KMeans(random_state = rNum, n_clusters = cNum)\n",
    "    #m.fit(kmerXTableInput) \n",
    "    #y_hat = km.predict(kmerXTableInput)\n",
    "    PCAembedding = PCA(n_components=10)\n",
    "    NkmerXTableInput = preprocessing.normalize(kmerXTableInput)\n",
    "    PCAembedding_low = PCAembedding.fit_transform(NkmerXTableInput)\n",
    "    \n",
    "    ms = MeanShift()\n",
    "    ms.fit(PCAembedding_low)\n",
    "    cluster_centers = ms.cluster_centers_\n",
    "\n",
    "    n_cluster_centers = len(cluster_centers)\n",
    "\n",
    "    import warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        kmms = KMeans(init = cluster_centers, n_clusters = n_cluster_centers)\n",
    "        #kmms = KMeans(init = 'k-means++', n_clusters = 2, n_init=20, max_iter=600)\n",
    "        y_hat = kmms.fit_predict(PCAembedding_low)\n",
    "    print(y_hat)\n",
    "    print(f\"n_cluster_centers: {n_cluster_centers}\")\n",
    "    if n_cluster_centers > cNum:\n",
    "        res = y_hat\n",
    "        unique_predicted_labels = get_unique_numbers(res)\n",
    "        predicted_labels_count = {}\n",
    "        for label in unique_predicted_labels:\n",
    "            predicted_labels_count[label] = (res == label).sum()\n",
    "        max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "        predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "        map_predict_to_actual = {}\n",
    "        max_value = cNum-1\n",
    "        for i in range(len(predicted_labels_count)):\n",
    "            if i < max_value:\n",
    "                map_predict_to_actual[predicted_labels_count[i][0]] = i\n",
    "            else:\n",
    "                # print(f\"{predicted_labels_count[i][0]} mapped to {max_value}\")\n",
    "                map_predict_to_actual[predicted_labels_count[i][0]] = max_value\n",
    "        print(f\"map_predict_to_actual: {map_predict_to_actual}\")\n",
    "        # predictions_final contains the final results\n",
    "        # it takes care of the case when num_class > number of unique labels given\n",
    "        predictions_final = []\n",
    "        # print(f\"res: {res}\")\n",
    "        # print(f\"map_predict_to_actual: {map_predict_to_actual}\")\n",
    "        for i in range(len(res)):\n",
    "            if res[i] in map_predict_to_actual.keys():\n",
    "                predictions_final.append(map_predict_to_actual[res[i]])\n",
    "            else:\n",
    "                predictions_final.append(map_predict_to_actual[max_item])\n",
    "        # print(predictions_final)\n",
    "        y_hat = np.array(predictions_final)\n",
    "\n",
    "        \n",
    "    return y_hat, kmerXTableInput\n",
    "\n",
    "def get_unique_numbers(numbers):\n",
    "\n",
    "    list_of_unique_numbers = []\n",
    "\n",
    "    unique_numbers = set(numbers)\n",
    "\n",
    "    for number in unique_numbers:\n",
    "        list_of_unique_numbers.append(number)\n",
    "\n",
    "    return list_of_unique_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MT994979.1</th>\n",
       "      <td>AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MZ043011.1</th>\n",
       "      <td>ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT994951.1</th>\n",
       "      <td>AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT994950.1</th>\n",
       "      <td>AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MW010029.1</th>\n",
       "      <td>AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Sequence\n",
       "ID                                                           \n",
       "MT994979.1  AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...\n",
       "MZ043011.1  ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGA...\n",
       "MT994951.1  AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...\n",
       "MT994950.1  AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...\n",
       "MW010029.1  AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./size_500_test.fasta\"\n",
    "ouput_df = parseFasta(path)\n",
    "ouput_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  3  0  0  0  0\n",
      "  0  0  0  0  0  2  0  0  0  0  1  0  0  0  2  0  1  2  1  0  0  0  0  0\n",
      "  0  0  0  2  0  2  0  1  0  0  0  0  0  0  0  0  0  1  0  0  2  0  1  1\n",
      "  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0\n",
      "  2  2  0  1  0  0  0  0  1  2  7  2  1  1  1  1  1  1  1  1  1  3  1  0\n",
      "  0  2  1  1  2  2  1  1  3  1  1  4  1  1  1  3  7  1  1  2  4  1  1  1\n",
      "  0  1  1  1  2  1  8  1  1  1  1  1  1  1  1  1  4  4  1  1  1  1  1  2\n",
      "  5  1  3  5  1  2  0  1  1  1  1  2  9  1  2  2 10  1  1  1  2  1  1  1\n",
      "  1  1  1  1  1  1  1  6  1  1  6  1  0  0  0  0  0  0  0  2  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  4  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "n_cluster_centers: 11\n",
      "map_predict_to_actual: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4, 6: 4, 7: 4, 8: 4, 9: 4, 10: 4}\n"
     ]
    }
   ],
   "source": [
    "from operator import mod\n",
    "\n",
    "\n",
    "fasta = \"./size_500_test.fasta\"\n",
    "klength_min = 3\n",
    "klength_max = 3\n",
    "cNum = 5\n",
    "seed = 1232\n",
    "predictions1, x = kmeans(fasta, cNum, klength_min, klength_max, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.stats import mode\n",
    "\n",
    "# # Assuming you have an array of 500 numbers stored in the variable 'numbers'\n",
    "# def get_accuracy(numbers):\n",
    "#     chunk_size = 100\n",
    "#     num_chunks = len(numbers) // chunk_size\n",
    "\n",
    "#     modes = []\n",
    "\n",
    "#     for i in range(num_chunks):\n",
    "#         chunk = numbers[i * chunk_size: (i + 1) * chunk_size]\n",
    "#         mode_result = mode(chunk)\n",
    "#         mode_value = mode_result.mode[0]\n",
    "#         mode_count = mode_result.count[0]\n",
    "#         modes.append((mode_value, mode_count))\n",
    "\n",
    "#     print(modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Matching': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}, 'Accuracy': 0.356}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Define the actual labels\n",
    "actual_labels = [0] * 100 + [1] * 100 + [2] * 100 + [3] * 100 + [4] * 100\n",
    "\n",
    "def get_accuracy(predicted_labels, actual_labels):\n",
    "    # Generate all possible permutations of label mappings\n",
    "    possible_mappings = list(itertools.permutations(set(predicted_labels)))\n",
    "\n",
    "    # Function to calculate accuracy given a label mapping\n",
    "    def calculate_accuracy(actual_labels, predicted_labels, mapping):\n",
    "        mapped_labels = [mapping[label] for label in predicted_labels]\n",
    "        correct_predictions = sum(1 for actual, predicted in zip(actual_labels, mapped_labels) if actual == predicted)\n",
    "        return correct_predictions / len(actual_labels)\n",
    "\n",
    "    # Find the mapping with the highest accuracy\n",
    "    best_mapping = None\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for mapping in possible_mappings:\n",
    "        accuracy = calculate_accuracy(actual_labels, predicted_labels, mapping)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_mapping = mapping\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "    # Create a dictionary containing the best matching and accuracy\n",
    "    matching_results = {\n",
    "        'Matching': dict(zip(set(predicted_labels), best_mapping)),\n",
    "        'Accuracy': best_accuracy\n",
    "    }\n",
    "\n",
    "    # Print the results\n",
    "    return matching_results\n",
    "\n",
    "best_mapping = get_accuracy(predictions1, actual_labels)\n",
    "print(best_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = [best_mapping['Matching'][label] for label in predictions1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = list(range(1, len(predictions1)+1))\n",
    "df = pd.DataFrame(list(zip(number, predictions1)), \n",
    "               columns =['Number', 'Labels']) \n",
    "df.to_csv('kmeans_unsup_predictions.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_label = pd.read_csv(\"./size_500_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents,columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([principalDf, pd.Series(predictions1)], axis = 1)\n",
    "finalDf = pd.concat([finalDf, pd.Series(actual_label['class'])], axis = 1)\n",
    "finalDf.columns = ['principal Component 1', 'Principal Component 2','Predicted Label', 'Actual Label']\n",
    "finalDf.to_csv('kmeans_unsup_pca.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.356"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(finalDf['Predicted Label'] == finalDf['Actual Label'])/len(finalDf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
